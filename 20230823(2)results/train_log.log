**train**
The number of data is 1964308
First data is ('2a6dad70-8a49-11ed-b776-0f38d08dc0cd', [2, 1, 2, 3, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1], [27, 36, 28, 29, 30, 31, 32, 33, 34, 35, 47, 48, 49, 49, 50, 51, 52, 53, 54, 55], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0], 81, 1)
**valid**
The number of data is 491078
First data is ('97fde2a0-95f0-11eb-91b8-9bc1a5afa09e', [10, 10, 21, 21, 21, 37, 6, 6, 6, 27, 22, 4, 10, 10, 10, 21, 21, 21, 22, 33, 22, 22, 6, 6, 6, 4, 4, 33, 21, 21, 33, 6, 28, 6, 15, 15, 15, 33, 33, 33, 21, 21, 22, 10, 10, 10, 6, 6, 21, 21, 21, 27, 26, 1, 28, 6, 6, 10, 10, 10, 4, 4, 21, 21, 33, 27, 6, 27, 6, 6, 10, 10, 10, 10, 10, 21, 21, 21, 22, 10, 10, 10, 6, 6, 33, 33, 21, 27, 26, 6, 6, 22, 22, 10, 10, 10, 21, 21, 21, 27], [1387, 1388, 1389, 1390, 1391, 1392, 1393, 1402, 1394, 1395, 1396, 1397, 1398, 1398, 1398, 1399, 1400, 1401, 1443, 1452, 1444, 1445, 1446, 1446, 1446, 1447, 1447, 1448, 1449, 1450, 1451, 1453, 1462, 1454, 1455, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1463, 1464, 1464, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1522, 1531, 1523, 1524, 1525, 1525, 1525, 1526, 1526, 1527, 1528, 1529, 1530, 1532, 1541, 1533, 1534, 1535, 1535, 1535, 1536, 1537, 1538, 1539, 1540, 1542, 1543, 1543, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1555, 1555, 1556, 1557, 1558, 1559], [1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 1608, 1)
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 99)]         0           []

 input_2 (InputLayer)           [(None, 99)]         0           []

 embedding_1 (Embedding)        (None, 99, 8)        312         ['input_1[0][0]']

 embedding (Embedding)          multiple             64768       ['input_2[0][0]',
                                                                  'input_4[0][0]']

 input_3 (InputLayer)           [(None, 99, 3)]      0           []

 concatenate (Concatenate)      (None, 99, 43)       0           ['embedding_1[0][0]',
                                                                  'embedding[0][0]',
                                                                  'input_3[0][0]']

 lstm (LSTM)                    (None, 99, 128)      88064       ['concatenate[0][0]']

 multi_head_attention (MultiHea  (None, 99, 128)     263808      ['lstm[0][0]',
 dAttention)                                                      'lstm[0][0]']

 tf.__operators__.add (TFOpLamb  (None, 99, 128)     0           ['lstm[0][0]',
 da)                                                              'multi_head_attention[0][0]']

 layer_normalization (LayerNorm  (None, 99, 128)     256         ['tf.__operators__.add[0][0]']
 alization)

 dropout (Dropout)              (None, 99, 128)      0           ['layer_normalization[0][0]']

 dense (Dense)                  (None, 99, 128)      16512       ['dropout[0][0]']

 input_4 (InputLayer)           [(None, 1)]          0           []

 dense_5 (Dense)                (None, 99, 2)        258         ['dense[0][0]']

 flatten (Flatten)              (None, 32)           0           ['embedding[1][0]']

 flatten_1 (Flatten)            (None, 198)          0           ['dense_5[0][0]']

 concatenate_1 (Concatenate)    (None, 230)          0           ['flatten[0][0]',
                                                                  'flatten_1[0][0]']

 dense_6 (Dense)                (None, 32)           7392        ['concatenate_1[0][0]']

 tf.__operators__.add_1 (TFOpLa  (None, 99, 128)     0           ['dropout[0][0]',
 mbda)                                                            'dense[0][0]']

 batch_normalization (BatchNorm  (None, 32)          128         ['dense_6[0][0]']
 alization)

 layer_normalization_1 (LayerNo  (None, 99, 128)     256         ['tf.__operators__.add_1[0][0]']
 rmalization)

 activation_1 (Activation)      (None, 32)           0           ['batch_normalization[0][0]']

 activation (Activation)        (None, 99, 128)      0           ['layer_normalization_1[0][0]']

 dense_7 (Dense)                (None, 32)           1056        ['activation_1[0][0]']

 dropout_1 (Dropout)            (None, 99, 128)      0           ['activation[0][0]']

 batch_normalization_1 (BatchNo  (None, 32)          128         ['dense_7[0][0]']
 rmalization)

 dense_1 (Dense)                (None, 99, 128)      16512       ['dropout_1[0][0]']

 activation_2 (Activation)      (None, 32)           0           ['batch_normalization_1[0][0]']

 dense_2 (Dense)                (None, 99, 39)       5031        ['dense_1[0][0]']

 dense_3 (Dense)                (None, 99, 2024)     261096      ['dense_1[0][0]']

 dense_4 (Dense)                (None, 99, 3)        387         ['dense_1[0][0]']

 dense_8 (Dense)                (None, 1)            33          ['activation_2[0][0]']

==================================================================================================
Total params: 725,997
Trainable params: 725,869
Non-trainable params: 128
__________________________________________________________________________________________________
Start Training...
Current time : 2023-09-20 22:47:08 KST, TensorFlow version :2.8.2
Current time : 2023-09-20 22:47:08 KST,  OS infromation :Linux
Current time : 2023-09-20 22:47:08 KST, OS version :#1 SMP Wed Jun 3 14:28:03 UTC 2020
Current time : 2023-09-20 22:47:08 KST,  Process information :x86_64
Current time : 2023-09-20 22:47:08 KST,  CPU_count :16
Current time : 2023-09-20 22:47:08 KST,  RAM_size :177(GB)
Epoch 1/10000
2023-09-20 13:47:18.884038: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100
3836/3836 [==============================] - 1937s 503ms/step - loss: 1.6670 - dense_2_loss: 0.1563 - dense_3_loss: 0.4611 - dense_4_loss: 0.2794 - dense_8_loss: 0.3851 - dense_2_accuracy: 0.9553 - dense_3_accuracy: 0.8977 - dense_4_accuracy: 0.8807 - dense_8_accuracy: 0.8240 - val_loss: 1.2475 - val_dense_2_loss: 0.0664 - val_dense_3_loss: 0.1760 - val_dense_4_loss: 0.2530 - val_dense_8_loss: 0.3760 - val_dense_2_accuracy: 0.9786 - val_dense_3_accuracy: 0.9522 - val_dense_4_accuracy: 0.8858 - val_dense_8_accuracy: 0.8326
Epoch 2/10000
3836/3836 [==============================] - 1843s 481ms/step - loss: 1.0660 - dense_2_loss: 0.0471 - dense_3_loss: 0.1155 - dense_4_loss: 0.1596 - dense_8_loss: 0.3719 - dense_2_accuracy: 0.9854 - dense_3_accuracy: 0.9688 - dense_4_accuracy: 0.9286 - dense_8_accuracy: 0.8331 - val_loss: 0.7574 - val_dense_2_loss: 7.7267e-04 - val_dense_3_loss: 0.0019 - val_dense_4_loss: 0.0049 - val_dense_8_loss: 0.3749 - val_dense_2_accuracy: 0.9998 - val_dense_3_accuracy: 0.9996 - val_dense_4_accuracy: 0.9980 - val_dense_8_accuracy: 0.8276
Epoch 3/10000
3836/3836 [==============================] - 1910s 498ms/step - loss: 0.7542 - dense_2_loss: 0.0027 - dense_3_loss: 0.0057 - dense_4_loss: 0.0060 - dense_8_loss: 0.3699 - dense_2_accuracy: 0.9993 - dense_3_accuracy: 0.9986 - dense_4_accuracy: 0.9978 - dense_8_accuracy: 0.8333 - val_loss: 0.7518 - val_dense_2_loss: 4.7943e-04 - val_dense_3_loss: 0.0011 - val_dense_4_loss: 0.0032 - val_dense_8_loss: 0.3735 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9984 - val_dense_8_accuracy: 0.8298
Epoch 4/10000
3836/3836 [==============================] - 1919s 500ms/step - loss: 0.7455 - dense_2_loss: 0.0016 - dense_3_loss: 0.0032 - dense_4_loss: 0.0040 - dense_8_loss: 0.3684 - dense_2_accuracy: 0.9996 - dense_3_accuracy: 0.9992 - dense_4_accuracy: 0.9983 - dense_8_accuracy: 0.8338 - val_loss: 0.7521 - val_dense_2_loss: 4.8175e-04 - val_dense_3_loss: 9.7751e-04 - val_dense_4_loss: 0.0031 - val_dense_8_loss: 0.3738 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9985 - val_dense_8_accuracy: 0.8236
Epoch 5/10000
3836/3836 [==============================] - 1851s 482ms/step - loss: 0.7419 - dense_2_loss: 0.0012 - dense_3_loss: 0.0025 - dense_4_loss: 0.0035 - dense_8_loss: 0.3673 - dense_2_accuracy: 0.9997 - dense_3_accuracy: 0.9994 - dense_4_accuracy: 0.9984 - dense_8_accuracy: 0.8341 - val_loss: 0.7616 - val_dense_2_loss: 4.0678e-04 - val_dense_3_loss: 8.5294e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3788 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8140
Epoch 6/10000
3836/3836 [==============================] - 1872s 488ms/step - loss: 0.7396 - dense_2_loss: 0.0010 - dense_3_loss: 0.0020 - dense_4_loss: 0.0033 - dense_8_loss: 0.3666 - dense_2_accuracy: 0.9997 - dense_3_accuracy: 0.9995 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8343 - val_loss: 0.7530 - val_dense_2_loss: 3.9711e-04 - val_dense_3_loss: 8.5857e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3745 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8196
Epoch 7/10000
3836/3836 [==============================] - 1861s 485ms/step - loss: 0.7378 - dense_2_loss: 9.2474e-04 - dense_3_loss: 0.0019 - dense_4_loss: 0.0032 - dense_8_loss: 0.3659 - dense_2_accuracy: 0.9997 - dense_3_accuracy: 0.9995 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8345 - val_loss: 0.7504 - val_dense_2_loss: 4.1098e-04 - val_dense_3_loss: 8.7558e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3731 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8226
Epoch 8/10000
3836/3836 [==============================] - 1847s 481ms/step - loss: 0.7362 - dense_2_loss: 8.4337e-04 - dense_3_loss: 0.0017 - dense_4_loss: 0.0032 - dense_8_loss: 0.3653 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8345 - val_loss: 0.7538 - val_dense_2_loss: 3.6188e-04 - val_dense_3_loss: 7.6325e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3750 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8179
Epoch 9/10000
3836/3836 [==============================] - 1834s 478ms/step - loss: 0.7349 - dense_2_loss: 8.0520e-04 - dense_3_loss: 0.0016 - dense_4_loss: 0.0031 - dense_8_loss: 0.3647 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8348 - val_loss: 0.7530 - val_dense_2_loss: 3.5829e-04 - val_dense_3_loss: 7.8362e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3745 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8189
Epoch 10/10000
3836/3836 [==============================] - 1878s 490ms/step - loss: 0.7335 - dense_2_loss: 7.7963e-04 - dense_3_loss: 0.0016 - dense_4_loss: 0.0031 - dense_8_loss: 0.3640 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8352 - val_loss: 0.7555 - val_dense_2_loss: 3.5089e-04 - val_dense_3_loss: 7.4287e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3758 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8161
Epoch 11/10000
3836/3836 [==============================] - 1881s 490ms/step - loss: 0.7322 - dense_2_loss: 7.4687e-04 - dense_3_loss: 0.0015 - dense_4_loss: 0.0031 - dense_8_loss: 0.3634 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8354 - val_loss: 0.7630 - val_dense_2_loss: 3.5101e-04 - val_dense_3_loss: 7.6746e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3795 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8092
Epoch 12/10000
3836/3836 [==============================] - 1807s 471ms/step - loss: 0.7308 - dense_2_loss: 7.4275e-04 - dense_3_loss: 0.0015 - dense_4_loss: 0.0031 - dense_8_loss: 0.3628 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8355 - val_loss: 0.7594 - val_dense_2_loss: 3.4595e-04 - val_dense_3_loss: 7.2570e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3778 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9985 - val_dense_8_accuracy: 0.8129
Epoch 13/10000
3836/3836 [==============================] - 1827s 476ms/step - loss: 0.7296 - dense_2_loss: 7.4656e-04 - dense_3_loss: 0.0015 - dense_4_loss: 0.0030 - dense_8_loss: 0.3622 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9986 - dense_8_accuracy: 0.8359 - val_loss: 0.7585 - val_dense_2_loss: 3.5935e-04 - val_dense_3_loss: 7.6306e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3773 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8129
Epoch 14/10000
3836/3836 [==============================] - 1871s 488ms/step - loss: 0.7281 - dense_2_loss: 7.4407e-04 - dense_3_loss: 0.0014 - dense_4_loss: 0.0030 - dense_8_loss: 0.3615 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9997 - dense_4_accuracy: 0.9986 - dense_8_accuracy: 0.8361 - val_loss: 0.7624 - val_dense_2_loss: 3.2941e-04 - val_dense_3_loss: 7.0052e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3793 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8114
Epoch 15/10000
3836/3836 [==============================] - 1833s 478ms/step - loss: 0.7268 - dense_2_loss: 7.4840e-04 - dense_3_loss: 0.0014 - dense_4_loss: 0.0030 - dense_8_loss: 0.3608 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9986 - dense_8_accuracy: 0.8363 - val_loss: 0.7594 - val_dense_2_loss: 3.4736e-04 - val_dense_3_loss: 7.2576e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3778 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8139
Epoch 16/10000
3836/3836 [==============================] - 1847s 481ms/step - loss: 0.7255 - dense_2_loss: 7.5783e-04 - dense_3_loss: 0.0014 - dense_4_loss: 0.0030 - dense_8_loss: 0.3601 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9986 - dense_8_accuracy: 0.8365 - val_loss: 0.7494 - val_dense_2_loss: 3.5236e-04 - val_dense_3_loss: 7.2913e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3728 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8236
Epoch 17/10000
3836/3836 [==============================] - 1877s 489ms/step - loss: 0.7241 - dense_2_loss: 7.8095e-04 - dense_3_loss: 0.0015 - dense_4_loss: 0.0030 - dense_8_loss: 0.3594 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8368 - val_loss: 0.7490 - val_dense_2_loss: 3.4499e-04 - val_dense_3_loss: 7.0599e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3726 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8245
Epoch 18/10000
3836/3836 [==============================] - 1864s 486ms/step - loss: 0.7229 - dense_2_loss: 7.9171e-04 - dense_3_loss: 0.0015 - dense_4_loss: 0.0030 - dense_8_loss: 0.3588 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9986 - dense_8_accuracy: 0.8370 - val_loss: 0.7477 - val_dense_2_loss: 3.3848e-04 - val_dense_3_loss: 7.1037e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3719 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8266
Epoch 19/10000
3836/3836 [==============================] - 1774s 463ms/step - loss: 0.7215 - dense_2_loss: 7.9627e-04 - dense_3_loss: 0.0015 - dense_4_loss: 0.0030 - dense_8_loss: 0.3581 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9986 - dense_8_accuracy: 0.8374 - val_loss: 0.7462 - val_dense_2_loss: 3.4025e-04 - val_dense_3_loss: 7.0191e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3712 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8273
Epoch 20/10000
3836/3836 [==============================] - 1869s 487ms/step - loss: 0.7201 - dense_2_loss: 8.0608e-04 - dense_3_loss: 0.0015 - dense_4_loss: 0.0031 - dense_8_loss: 0.3574 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9986 - dense_8_accuracy: 0.8376 - val_loss: 0.7457 - val_dense_2_loss: 3.4692e-04 - val_dense_3_loss: 7.1451e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3710 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8296
Epoch 21/10000
3836/3836 [==============================] - 1877s 489ms/step - loss: 0.7189 - dense_2_loss: 8.2887e-04 - dense_3_loss: 0.0015 - dense_4_loss: 0.0031 - dense_8_loss: 0.3567 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9986 - dense_8_accuracy: 0.8378 - val_loss: 0.7458 - val_dense_2_loss: 3.6784e-04 - val_dense_3_loss: 7.4805e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3710 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8289
Epoch 22/10000
3836/3836 [==============================] - 1822s 475ms/step - loss: 0.7177 - dense_2_loss: 8.4657e-04 - dense_3_loss: 0.0015 - dense_4_loss: 0.0031 - dense_8_loss: 0.3561 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8382 - val_loss: 0.7435 - val_dense_2_loss: 3.5343e-04 - val_dense_3_loss: 6.9133e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3699 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8315
Epoch 23/10000
3836/3836 [==============================] - 1853s 483ms/step - loss: 0.7165 - dense_2_loss: 8.5556e-04 - dense_3_loss: 0.0016 - dense_4_loss: 0.0031 - dense_8_loss: 0.3555 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8385 - val_loss: 0.7455 - val_dense_2_loss: 3.5930e-04 - val_dense_3_loss: 7.0467e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3708 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8327
Epoch 24/10000
3836/3836 [==============================] - 1848s 482ms/step - loss: 0.7153 - dense_2_loss: 8.7569e-04 - dense_3_loss: 0.0016 - dense_4_loss: 0.0031 - dense_8_loss: 0.3549 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8386 - val_loss: 0.7443 - val_dense_2_loss: 3.4729e-04 - val_dense_3_loss: 7.1845e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3703 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8335
Epoch 25/10000
3836/3836 [==============================] - 1843s 480ms/step - loss: 0.7142 - dense_2_loss: 8.7808e-04 - dense_3_loss: 0.0016 - dense_4_loss: 0.0031 - dense_8_loss: 0.3543 - dense_2_accuracy: 0.9998 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8389 - val_loss: 0.7444 - val_dense_2_loss: 3.5938e-04 - val_dense_3_loss: 7.0625e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3703 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8330
Epoch 26/10000
3836/3836 [==============================] - 1823s 475ms/step - loss: 0.7130 - dense_2_loss: 9.0525e-04 - dense_3_loss: 0.0016 - dense_4_loss: 0.0031 - dense_8_loss: 0.3537 - dense_2_accuracy: 0.9997 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8390 - val_loss: 0.7483 - val_dense_2_loss: 3.7829e-04 - val_dense_3_loss: 7.2840e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3722 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8367
Epoch 27/10000
3836/3836 [==============================] - 1875s 489ms/step - loss: 0.7118 - dense_2_loss: 9.1568e-04 - dense_3_loss: 0.0016 - dense_4_loss: 0.0031 - dense_8_loss: 0.3531 - dense_2_accuracy: 0.9997 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8395 - val_loss: 0.7474 - val_dense_2_loss: 3.9133e-04 - val_dense_3_loss: 7.3197e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3718 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8349
Epoch 28/10000
3836/3836 [==============================] - 1880s 490ms/step - loss: 0.7109 - dense_2_loss: 9.2457e-04 - dense_3_loss: 0.0016 - dense_4_loss: 0.0031 - dense_8_loss: 0.3526 - dense_2_accuracy: 0.9997 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8396 - val_loss: 0.7503 - val_dense_2_loss: 3.7051e-04 - val_dense_3_loss: 7.2906e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3732 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8364
Epoch 29/10000
3836/3836 [==============================] - 1832s 478ms/step - loss: 0.7098 - dense_2_loss: 9.3133e-04 - dense_3_loss: 0.0016 - dense_4_loss: 0.0031 - dense_8_loss: 0.3521 - dense_2_accuracy: 0.9997 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8398 - val_loss: 0.7529 - val_dense_2_loss: 3.7296e-04 - val_dense_3_loss: 7.1700e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3745 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8373
Epoch 30/10000
3836/3836 [==============================] - 1822s 475ms/step - loss: 0.7088 - dense_2_loss: 9.4261e-04 - dense_3_loss: 0.0016 - dense_4_loss: 0.0031 - dense_8_loss: 0.3516 - dense_2_accuracy: 0.9997 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8401 - val_loss: 0.7561 - val_dense_2_loss: 3.8312e-04 - val_dense_3_loss: 7.4115e-04 - val_dense_4_loss: 0.0028 - val_dense_8_loss: 0.3761 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8376
Epoch 31/10000
3836/3836 [==============================] - 1860s 485ms/step - loss: 0.7079 - dense_2_loss: 9.5330e-04 - dense_3_loss: 0.0016 - dense_4_loss: 0.0031 - dense_8_loss: 0.3511 - dense_2_accuracy: 0.9997 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8401 - val_loss: 0.7539 - val_dense_2_loss: 3.8937e-04 - val_dense_3_loss: 7.3851e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3750 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8371
Epoch 32/10000
3836/3836 [==============================] - 1832s 478ms/step - loss: 0.7070 - dense_2_loss: 9.6878e-04 - dense_3_loss: 0.0017 - dense_4_loss: 0.0031 - dense_8_loss: 0.3506 - dense_2_accuracy: 0.9997 - dense_3_accuracy: 0.9996 - dense_4_accuracy: 0.9985 - dense_8_accuracy: 0.8404 - val_loss: 0.7578 - val_dense_2_loss: 3.8658e-04 - val_dense_3_loss: 7.1950e-04 - val_dense_4_loss: 0.0027 - val_dense_8_loss: 0.3770 - val_dense_2_accuracy: 0.9999 - val_dense_3_accuracy: 0.9998 - val_dense_4_accuracy: 0.9986 - val_dense_8_accuracy: 0.8382
Finish Traning...
Current time : 2023-09-21 15:16:41 KST
**train**
The number of data is 63087
First data is ('000120a0-eee8-11ec-8b96-254279cd1714', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8], [523, 523, 524, 524, 525, 526, 527, 528, 529, 530, 531, 531, 532, 532, 533, 534, 535, 536, 537, 538, 547, 556, 548, 549, 550, 551, 552, 553, 554, 555, 693, 702, 694, 695, 696, 697, 698, 699, 700, 701, 703, 704, 705, 705, 706, 707, 708, 709, 710, 711, 712, 721, 713, 713, 714, 715, 716, 717, 718, 719, 720], [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])
**valid**
The number of data is 21103
First data is ('000ce720-e158-11ec-8870-5d4cb3b98715', [4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3], [131, 140, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 143, 144, 145, 146, 147, 148, 149], [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
**test**
The number of data is 20745
First data is ('00037820-bdf4-11ec-aad8-4fc760357a97', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
Before Remapping, max value of index 1 is 40
{3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8, 11: 9, 12: 10, 13: 11, 14: 12, 15: 13, 16: 14, 17: 15, 18: 16, 19: 17, 20: 18, 21: 19, 22: 20, 23: 21, 24: 22, 25: 23, 26: 24, 27: 25, 28: 26, 29: 27, 30: 28, 31: 29, 32: 30, 33: 31, 34: 32, 35: 33, 36: 34, 37: 35, 38: 36, 39: 37, 40: 38}
After Remapping, max value of index 1 is 38
Before Remapping, max value of index 2 is 2661
{6: 1, 7: 2, 13: 3, 14: 4, 15: 5, 21: 6, 22: 7, 23: 8, 29: 9, 30: 10, 31: 11, 38: 12, 39: 13, 66: 14, 67: 15, 73: 16, 74: 17, 75: 18, 81: 19, 82: 20, 83: 21, 90: 22, 91: 23, 97: 24, 98: 25, 99: 26, 121: 27, 122: 28, 123: 29, 124: 30, 125: 31, 126: 32, 127: 33, 128: 34, 129: 35, 130: 36, 131: 37, 132: 38, 133: 39, 134: 40, 135: 41, 136: 42, 137: 43, 138: 44, 139: 45, 140: 46, 141: 47, 142: 48, 143: 49, 144: 50, 145: 51, 146: 52, 147: 53, 148: 54, 149: 55, 150: 56, 151: 57, 152: 58, 153: 59, 154: 60, 155: 61, 156: 62, 157: 63, 158: 64, 159: 65, 160: 66, 161: 67, 162: 68, 163: 69, 164: 70, 165: 71, 166: 72, 167: 73, 168: 74, 169: 75, 170: 76, 171: 77, 172: 78, 173: 79, 174: 80, 175: 81, 176: 82, 177: 83, 178: 84, 179: 85, 180: 86, 181: 87, 182: 88, 183: 89, 184: 90, 185: 91, 186: 92, 187: 93, 188: 94, 189: 95, 190: 96, 191: 97, 192: 98, 193: 99, 194: 100, 195: 101, 196: 102, 197: 103, 198: 104, 199: 105, 200: 106, 201: 107, 202: 108, 203: 109, 204: 110, 205: 111, 206: 112, 207: 113, 208: 114, 209: 115, 210: 116, 211: 117, 212: 118, 213: 119, 214: 120, 215: 121, 216: 122, 217: 123, 218: 124, 219: 125, 220: 126, 221: 127, 222: 128, 223: 129, 224: 130, 225: 131, 226: 132, 227: 133, 228: 134, 229: 135, 230: 136, 231: 137, 232: 138, 233: 139, 234: 140, 235: 141, 236: 142, 237: 143, 238: 144, 239: 145, 240: 146, 241: 147, 242: 148, 243: 149, 244: 150, 245: 151, 246: 152, 247: 153, 248: 154, 249: 155, 250: 156, 260: 157, 261: 158, 262: 159, 263: 160, 264: 161, 265: 162, 266: 163, 267: 164, 295: 165, 296: 166, 297: 167, 298: 168, 299: 169, 300: 170, 301: 171, 302: 172, 303: 173, 304: 174, 305: 175, 306: 176, 307: 177, 308: 178, 309: 179, 310: 180, 311: 181, 312: 182, 313: 183, 314: 184, 315: 185, 316: 186, 317: 187, 318: 188, 319: 189, 320: 190, 321: 191, 322: 192, 323: 193, 324: 194, 325: 195, 326: 196, 327: 197, 328: 198, 329: 199, 330: 200, 331: 201, 332: 202, 333: 203, 334: 204, 335: 205, 336: 206, 337: 207, 338: 208, 339: 209, 340: 210, 341: 211, 342: 212, 343: 213, 344: 214, 345: 215, 346: 216, 347: 217, 348: 218, 349: 219, 350: 220, 351: 221, 352: 222, 353: 223, 354: 224, 355: 225, 356: 226, 357: 227, 358: 228, 359: 229, 360: 230, 361: 231, 362: 232, 363: 233, 364: 234, 365: 235, 366: 236, 367: 237, 368: 238, 369: 239, 370: 240, 371: 241, 372: 242, 373: 243, 374: 244, 375: 245, 376: 246, 377: 247, 378: 248, 379: 249, 380: 250, 381: 251, 382: 252, 383: 253, 384: 254, 385: 255, 386: 256, 387: 257, 388: 258, 389: 259, 412: 260, 413: 261, 414: 262, 415: 263, 416: 264, 417: 265, 418: 266, 419: 267, 420: 268, 421: 269, 422: 270, 423: 271, 424: 272, 425: 273, 426: 274, 427: 275, 428: 276, 429: 277, 430: 278, 431: 279, 432: 280, 433: 281, 434: 282, 435: 283, 436: 284, 437: 285, 438: 286, 439: 287, 440: 288, 441: 289, 442: 290, 443: 291, 444: 292, 445: 293, 446: 294, 447: 295, 448: 296, 449: 297, 450: 298, 451: 299, 452: 300, 453: 301, 454: 302, 455: 303, 456: 304, 457: 305, 458: 306, 459: 307, 460: 308, 461: 309, 462: 310, 463: 311, 464: 312, 465: 313, 466: 314, 467: 315, 468: 316, 469: 317, 470: 318, 471: 319, 472: 320, 473: 321, 474: 322, 475: 323, 476: 324, 477: 325, 478: 326, 479: 327, 480: 328, 481: 329, 482: 330, 483: 331, 484: 332, 485: 333, 486: 334, 507: 335, 508: 336, 509: 337, 510: 338, 511: 339, 512: 340, 513: 341, 514: 342, 515: 343, 516: 344, 517: 345, 518: 346, 519: 347, 520: 348, 521: 349, 522: 350, 523: 351, 524: 352, 525: 353, 526: 354, 527: 355, 528: 356, 529: 357, 530: 358, 531: 359, 532: 360, 533: 361, 534: 362, 535: 363, 536: 364, 537: 365, 538: 366, 539: 367, 540: 368, 541: 369, 542: 370, 543: 371, 544: 372, 545: 373, 546: 374, 547: 375, 548: 376, 549: 377, 550: 378, 551: 379, 552: 380, 553: 381, 554: 382, 555: 383, 556: 384, 557: 385, 558: 386, 559: 387, 560: 388, 561: 389, 562: 390, 563: 391, 564: 392, 565: 393, 566: 394, 567: 395, 568: 396, 569: 397, 570: 398, 571: 399, 572: 400, 573: 401, 574: 402, 575: 403, 576: 404, 577: 405, 578: 406, 579: 407, 580: 408, 581: 409, 582: 410, 583: 411, 584: 412, 585: 413, 586: 414, 587: 415, 588: 416, 589: 417, 590: 418, 591: 419, 592: 420, 593: 421, 594: 422, 595: 423, 596: 424, 597: 425, 598: 426, 599: 427, 600: 428, 601: 429, 602: 430, 603: 431, 604: 432, 605: 433, 606: 434, 607: 435, 608: 436, 609: 437, 610: 438, 611: 439, 612: 440, 613: 441, 614: 442, 615: 443, 616: 444, 617: 445, 618: 446, 619: 447, 620: 448, 621: 449, 622: 450, 623: 451, 624: 452, 625: 453, 626: 454, 627: 455, 628: 456, 629: 457, 630: 458, 631: 459, 632: 460, 633: 461, 634: 462, 635: 463, 636: 464, 637: 465, 638: 466, 639: 467, 640: 468, 641: 469, 642: 470, 643: 471, 644: 472, 645: 473, 677: 474, 678: 475, 679: 476, 680: 477, 681: 478, 682: 479, 683: 480, 684: 481, 685: 482, 686: 483, 687: 484, 688: 485, 689: 486, 690: 487, 691: 488, 692: 489, 693: 490, 694: 491, 695: 492, 696: 493, 697: 494, 698: 495, 699: 496, 700: 497, 701: 498, 702: 499, 703: 500, 704: 501, 705: 502, 706: 503, 707: 504, 708: 505, 709: 506, 710: 507, 711: 508, 712: 509, 713: 510, 714: 511, 715: 512, 716: 513, 717: 514, 718: 515, 719: 516, 720: 517, 721: 518, 722: 519, 723: 520, 724: 521, 725: 522, 726: 523, 727: 524, 728: 525, 729: 526, 730: 527, 731: 528, 732: 529, 733: 530, 734: 531, 735: 532, 736: 533, 737: 534, 738: 535, 739: 536, 740: 537, 741: 538, 742: 539, 743: 540, 744: 541, 745: 542, 746: 543, 747: 544, 748: 545, 749: 546, 750: 547, 751: 548, 752: 549, 753: 550, 754: 551, 755: 552, 756: 553, 757: 554, 758: 555, 759: 556, 780: 557, 781: 558, 782: 559, 783: 560, 784: 561, 785: 562, 786: 563, 787: 564, 788: 565, 789: 566, 790: 567, 791: 568, 792: 569, 793: 570, 794: 571, 795: 572, 796: 573, 797: 574, 798: 575, 799: 576, 800: 577, 801: 578, 802: 579, 803: 580, 804: 581, 805: 582, 806: 583, 807: 584, 808: 585, 809: 586, 810: 587, 811: 588, 812: 589, 813: 590, 814: 591, 815: 592, 816: 593, 817: 594, 818: 595, 819: 596, 820: 597, 821: 598, 822: 599, 823: 600, 824: 601, 825: 602, 826: 603, 827: 604, 828: 605, 829: 606, 830: 607, 831: 608, 832: 609, 833: 610, 834: 611, 835: 612, 836: 613, 837: 614, 838: 615, 839: 616, 840: 617, 841: 618, 842: 619, 843: 620, 844: 621, 845: 622, 846: 623, 847: 624, 848: 625, 849: 626, 869: 627, 870: 628, 871: 629, 872: 630, 873: 631, 874: 632, 875: 633, 876: 634, 877: 635, 878: 636, 879: 637, 880: 638, 881: 639, 882: 640, 883: 641, 884: 642, 885: 643, 886: 644, 887: 645, 888: 646, 889: 647, 890: 648, 891: 649, 892: 650, 893: 651, 894: 652, 895: 653, 896: 654, 897: 655, 898: 656, 899: 657, 900: 658, 901: 659, 902: 660, 903: 661, 904: 662, 905: 663, 906: 664, 907: 665, 908: 666, 909: 667, 910: 668, 911: 669, 912: 670, 913: 671, 914: 672, 915: 673, 916: 674, 917: 675, 918: 676, 919: 677, 920: 678, 921: 679, 922: 680, 923: 681, 924: 682, 925: 683, 926: 684, 927: 685, 928: 686, 929: 687, 930: 688, 931: 689, 932: 690, 933: 691, 934: 692, 935: 693, 936: 694, 937: 695, 938: 696, 939: 697, 940: 698, 941: 699, 942: 700, 943: 701, 944: 702, 945: 703, 946: 704, 947: 705, 948: 706, 949: 707, 950: 708, 951: 709, 952: 710, 953: 711, 954: 712, 955: 713, 956: 714, 957: 715, 958: 716, 959: 717, 960: 718, 961: 719, 962: 720, 963: 721, 964: 722, 965: 723, 966: 724, 967: 725, 968: 726, 969: 727, 970: 728, 971: 729, 972: 730, 973: 731, 974: 732, 975: 733, 976: 734, 977: 735, 978: 736, 979: 737, 980: 738, 981: 739, 982: 740, 983: 741, 984: 742, 985: 743, 986: 744, 987: 745, 988: 746, 989: 747, 990: 748, 991: 749, 992: 750, 993: 751, 994: 752, 995: 753, 996: 754, 997: 755, 998: 756, 999: 757, 1000: 758, 1001: 759, 1002: 760, 1037: 761, 1038: 762, 1039: 763, 1040: 764, 1041: 765, 1042: 766, 1043: 767, 1044: 768, 1045: 769, 1046: 770, 1047: 771, 1048: 772, 1049: 773, 1050: 774, 1051: 775, 1052: 776, 1053: 777, 1054: 778, 1055: 779, 1056: 780, 1057: 781, 1058: 782, 1059: 783, 1060: 784, 1061: 785, 1062: 786, 1063: 787, 1064: 788, 1065: 789, 1066: 790, 1067: 791, 1068: 792, 1069: 793, 1070: 794, 1071: 795, 1072: 796, 1073: 797, 1074: 798, 1075: 799, 1076: 800, 1077: 801, 1078: 802, 1079: 803, 1080: 804, 1081: 805, 1082: 806, 1083: 807, 1084: 808, 1085: 809, 1086: 810, 1087: 811, 1088: 812, 1089: 813, 1090: 814, 1091: 815, 1092: 816, 1093: 817, 1094: 818, 1095: 819, 1096: 820, 1097: 821, 1098: 822, 1099: 823, 1100: 824, 1101: 825, 1102: 826, 1103: 827, 1104: 828, 1105: 829, 1106: 830, 1107: 831, 1108: 832, 1109: 833, 1110: 834, 1111: 835, 1112: 836, 1113: 837, 1114: 838, 1115: 839, 1136: 840, 1137: 841, 1138: 842, 1139: 843, 1140: 844, 1141: 845, 1142: 846, 1143: 847, 1144: 848, 1145: 849, 1146: 850, 1147: 851, 1148: 852, 1149: 853, 1150: 854, 1151: 855, 1152: 856, 1153: 857, 1154: 858, 1155: 859, 1156: 860, 1157: 861, 1158: 862, 1159: 863, 1160: 864, 1161: 865, 1162: 866, 1163: 867, 1164: 868, 1165: 869, 1166: 870, 1167: 871, 1168: 872, 1169: 873, 1170: 874, 1171: 875, 1172: 876, 1173: 877, 1174: 878, 1175: 879, 1176: 880, 1177: 881, 1178: 882, 1179: 883, 1180: 884, 1181: 885, 1182: 886, 1183: 887, 1184: 888, 1185: 889, 1186: 890, 1187: 891, 1188: 892, 1189: 893, 1190: 894, 1191: 895, 1192: 896, 1193: 897, 1194: 898, 1195: 899, 1196: 900, 1197: 901, 1198: 902, 1199: 903, 1200: 904, 1201: 905, 1202: 906, 1203: 907, 1204: 908, 1205: 909, 1206: 910, 1227: 911, 1228: 912, 1229: 913, 1230: 914, 1231: 915, 1232: 916, 1233: 917, 1234: 918, 1235: 919, 1236: 920, 1237: 921, 1238: 922, 1239: 923, 1240: 924, 1241: 925, 1242: 926, 1243: 927, 1244: 928, 1245: 929, 1246: 930, 1247: 931, 1248: 932, 1249: 933, 1250: 934, 1251: 935, 1252: 936, 1253: 937, 1254: 938, 1255: 939, 1256: 940, 1257: 941, 1258: 942, 1259: 943, 1260: 944, 1261: 945, 1262: 946, 1263: 947, 1264: 948, 1265: 949, 1266: 950, 1267: 951, 1268: 952, 1269: 953, 1270: 954, 1271: 955, 1272: 956, 1273: 957, 1274: 958, 1275: 959, 1276: 960, 1277: 961, 1278: 962, 1279: 963, 1280: 964, 1281: 965, 1282: 966, 1283: 967, 1284: 968, 1285: 969, 1286: 970, 1287: 971, 1288: 972, 1289: 973, 1290: 974, 1291: 975, 1292: 976, 1293: 977, 1294: 978, 1295: 979, 1296: 980, 1297: 981, 1298: 982, 1320: 983, 1321: 984, 1322: 985, 1323: 986, 1324: 987, 1325: 988, 1326: 989, 1327: 990, 1328: 991, 1329: 992, 1330: 993, 1331: 994, 1332: 995, 1333: 996, 1334: 997, 1335: 998, 1336: 999, 1337: 1000, 1338: 1001, 1339: 1002, 1340: 1003, 1341: 1004, 1342: 1005, 1343: 1006, 1344: 1007, 1345: 1008, 1346: 1009, 1347: 1010, 1348: 1011, 1349: 1012, 1358: 1013, 1359: 1014, 1360: 1015, 1361: 1016, 1362: 1017, 1363: 1018, 1364: 1019, 1365: 1020, 1366: 1021, 1367: 1022, 1368: 1023, 1369: 1024, 1370: 1025, 1371: 1026, 1372: 1027, 1373: 1028, 1374: 1029, 1375: 1030, 1376: 1031, 1377: 1032, 1378: 1033, 1379: 1034, 1380: 1035, 1381: 1036, 1382: 1037, 1383: 1038, 1384: 1039, 1385: 1040, 1386: 1041, 1397: 1042, 1398: 1043, 1399: 1044, 1400: 1045, 1401: 1046, 1402: 1047, 1403: 1048, 1404: 1049, 1419: 1050, 1420: 1051, 1421: 1052, 1422: 1053, 1423: 1054, 1424: 1055, 1425: 1056, 1426: 1057, 1427: 1058, 1428: 1059, 1429: 1060, 1430: 1061, 1431: 1062, 1432: 1063, 1433: 1064, 1434: 1065, 1435: 1066, 1436: 1067, 1437: 1068, 1438: 1069, 1439: 1070, 1440: 1071, 1441: 1072, 1442: 1073, 1443: 1074, 1444: 1075, 1445: 1076, 1446: 1077, 1447: 1078, 1448: 1079, 1449: 1080, 1450: 1081, 1451: 1082, 1452: 1083, 1453: 1084, 1454: 1085, 1455: 1086, 1456: 1087, 1457: 1088, 1458: 1089, 1459: 1090, 1460: 1091, 1461: 1092, 1462: 1093, 1463: 1094, 1464: 1095, 1465: 1096, 1466: 1097, 1467: 1098, 1468: 1099, 1469: 1100, 1470: 1101, 1471: 1102, 1472: 1103, 1473: 1104, 1474: 1105, 1475: 1106, 1476: 1107, 1477: 1108, 1478: 1109, 1479: 1110, 1480: 1111, 1481: 1112, 1482: 1113, 1483: 1114, 1484: 1115, 1485: 1116, 1486: 1117, 1487: 1118, 1488: 1119, 1489: 1120, 1490: 1121, 1491: 1122, 1492: 1123, 1493: 1124, 1494: 1125, 1495: 1126, 1496: 1127, 1519: 1128, 1520: 1129, 1521: 1130, 1522: 1131, 1523: 1132, 1524: 1133, 1525: 1134, 1526: 1135, 1527: 1136, 1528: 1137, 1529: 1138, 1530: 1139, 1531: 1140, 1532: 1141, 1533: 1142, 1534: 1143, 1535: 1144, 1536: 1145, 1537: 1146, 1538: 1147, 1539: 1148, 1540: 1149, 1541: 1150, 1542: 1151, 1543: 1152, 1544: 1153, 1545: 1154, 1546: 1155, 1547: 1156, 1548: 1157, 1549: 1158, 1550: 1159, 1551: 1160, 1552: 1161, 1553: 1162, 1554: 1163, 1555: 1164, 1556: 1165, 1557: 1166, 1558: 1167, 1559: 1168, 1560: 1169, 1561: 1170, 1562: 1171, 1563: 1172, 1564: 1173, 1565: 1174, 1566: 1175, 1567: 1176, 1568: 1177, 1569: 1178, 1570: 1179, 1571: 1180, 1572: 1181, 1573: 1182, 1574: 1183, 1575: 1184, 1576: 1185, 1577: 1186, 1578: 1187, 1579: 1188, 1580: 1189, 1581: 1190, 1582: 1191, 1583: 1192, 1584: 1193, 1585: 1194, 1586: 1195, 1587: 1196, 1588: 1197, 1589: 1198, 1590: 1199, 1591: 1200, 1612: 1201, 1613: 1202, 1614: 1203, 1615: 1204, 1616: 1205, 1617: 1206, 1618: 1207, 1619: 1208, 1620: 1209, 1621: 1210, 1622: 1211, 1623: 1212, 1624: 1213, 1625: 1214, 1626: 1215, 1627: 1216, 1628: 1217, 1629: 1218, 1630: 1219, 1631: 1220, 1632: 1221, 1633: 1222, 1634: 1223, 1635: 1224, 1636: 1225, 1637: 1226, 1638: 1227, 1639: 1228, 1640: 1229, 1641: 1230, 1642: 1231, 1643: 1232, 1644: 1233, 1645: 1234, 1646: 1235, 1647: 1236, 1648: 1237, 1649: 1238, 1650: 1239, 1651: 1240, 1652: 1241, 1653: 1242, 1654: 1243, 1655: 1244, 1656: 1245, 1657: 1246, 1658: 1247, 1659: 1248, 1660: 1249, 1661: 1250, 1662: 1251, 1663: 1252, 1664: 1253, 1665: 1254, 1666: 1255, 1667: 1256, 1668: 1257, 1669: 1258, 1670: 1259, 1671: 1260, 1672: 1261, 1673: 1262, 1674: 1263, 1675: 1264, 1676: 1265, 1677: 1266, 1678: 1267, 1679: 1268, 1680: 1269, 1681: 1270, 1682: 1271, 1683: 1272, 1684: 1273, 1706: 1274, 1707: 1275, 1708: 1276, 1709: 1277, 1710: 1278, 1711: 1279, 1712: 1280, 1713: 1281, 1714: 1282, 1715: 1283, 1716: 1284, 1717: 1285, 1718: 1286, 1719: 1287, 1720: 1288, 1721: 1289, 1722: 1290, 1723: 1291, 1724: 1292, 1725: 1293, 1726: 1294, 1727: 1295, 1728: 1296, 1729: 1297, 1730: 1298, 1731: 1299, 1732: 1300, 1733: 1301, 1734: 1302, 1735: 1303, 1736: 1304, 1737: 1305, 1738: 1306, 1739: 1307, 1740: 1308, 1741: 1309, 1742: 1310, 1743: 1311, 1744: 1312, 1745: 1313, 1746: 1314, 1747: 1315, 1748: 1316, 1749: 1317, 1750: 1318, 1751: 1319, 1752: 1320, 1753: 1321, 1754: 1322, 1755: 1323, 1756: 1324, 1757: 1325, 1758: 1326, 1759: 1327, 1760: 1328, 1761: 1329, 1762: 1330, 1763: 1331, 1764: 1332, 1765: 1333, 1766: 1334, 1767: 1335, 1768: 1336, 1769: 1337, 1770: 1338, 1771: 1339, 1772: 1340, 1773: 1341, 1774: 1342, 1775: 1343, 1776: 1344, 1777: 1345, 1778: 1346, 1779: 1347, 1780: 1348, 1781: 1349, 1782: 1350, 1783: 1351, 1784: 1352, 1807: 1353, 1808: 1354, 1809: 1355, 1810: 1356, 1811: 1357, 1812: 1358, 1813: 1359, 1814: 1360, 1815: 1361, 1816: 1362, 1817: 1363, 1818: 1364, 1819: 1365, 1820: 1366, 1821: 1367, 1822: 1368, 1823: 1369, 1824: 1370, 1825: 1371, 1826: 1372, 1827: 1373, 1828: 1374, 1829: 1375, 1830: 1376, 1831: 1377, 1832: 1378, 1833: 1379, 1834: 1380, 1835: 1381, 1836: 1382, 1837: 1383, 1838: 1384, 1839: 1385, 1840: 1386, 1841: 1387, 1842: 1388, 1843: 1389, 1844: 1390, 1845: 1391, 1846: 1392, 1847: 1393, 1848: 1394, 1849: 1395, 1850: 1396, 1851: 1397, 1852: 1398, 1853: 1399, 1854: 1400, 1855: 1401, 1856: 1402, 1857: 1403, 1858: 1404, 1859: 1405, 1860: 1406, 1861: 1407, 1862: 1408, 1863: 1409, 1864: 1410, 1865: 1411, 1866: 1412, 1867: 1413, 1868: 1414, 1869: 1415, 1870: 1416, 1871: 1417, 1872: 1418, 1873: 1419, 1874: 1420, 1875: 1421, 1876: 1422, 1877: 1423, 1878: 1424, 1879: 1425, 1880: 1426, 1881: 1427, 1882: 1428, 1883: 1429, 1884: 1430, 1885: 1431, 1909: 1432, 1910: 1433, 1911: 1434, 1912: 1435, 1913: 1436, 1914: 1437, 1915: 1438, 1916: 1439, 1917: 1440, 1918: 1441, 1919: 1442, 1920: 1443, 1921: 1444, 1922: 1445, 1923: 1446, 1924: 1447, 1925: 1448, 1926: 1449, 1927: 1450, 1928: 1451, 1929: 1452, 1930: 1453, 1931: 1454, 1932: 1455, 1933: 1456, 1934: 1457, 1935: 1458, 1936: 1459, 1937: 1460, 1938: 1461, 1939: 1462, 1940: 1463, 1941: 1464, 1942: 1465, 1943: 1466, 1944: 1467, 1945: 1468, 1946: 1469, 1947: 1470, 1948: 1471, 1949: 1472, 1950: 1473, 1951: 1474, 1952: 1475, 1953: 1476, 1954: 1477, 1955: 1478, 1956: 1479, 1957: 1480, 1958: 1481, 1959: 1482, 1960: 1483, 1961: 1484, 1962: 1485, 1963: 1486, 1964: 1487, 1965: 1488, 1966: 1489, 1967: 1490, 1968: 1491, 1969: 1492, 1970: 1493, 1971: 1494, 1972: 1495, 1973: 1496, 1974: 1497, 1975: 1498, 1976: 1499, 1977: 1500, 1978: 1501, 1979: 1502, 1980: 1503, 1981: 1504, 1982: 1505, 1983: 1506, 1984: 1507, 1985: 1508, 1986: 1509, 1987: 1510, 2011: 1511, 2012: 1512, 2013: 1513, 2014: 1514, 2015: 1515, 2016: 1516, 2017: 1517, 2018: 1518, 2019: 1519, 2020: 1520, 2021: 1521, 2022: 1522, 2023: 1523, 2024: 1524, 2025: 1525, 2026: 1526, 2027: 1527, 2028: 1528, 2029: 1529, 2030: 1530, 2031: 1531, 2032: 1532, 2033: 1533, 2034: 1534, 2035: 1535, 2036: 1536, 2037: 1537, 2038: 1538, 2039: 1539, 2040: 1540, 2041: 1541, 2042: 1542, 2043: 1543, 2044: 1544, 2045: 1545, 2046: 1546, 2047: 1547, 2048: 1548, 2049: 1549, 2050: 1550, 2051: 1551, 2052: 1552, 2053: 1553, 2054: 1554, 2055: 1555, 2056: 1556, 2057: 1557, 2058: 1558, 2059: 1559, 2060: 1560, 2061: 1561, 2062: 1562, 2063: 1563, 2064: 1564, 2065: 1565, 2066: 1566, 2067: 1567, 2068: 1568, 2069: 1569, 2070: 1570, 2071: 1571, 2072: 1572, 2073: 1573, 2074: 1574, 2075: 1575, 2076: 1576, 2077: 1577, 2078: 1578, 2079: 1579, 2080: 1580, 2081: 1581, 2082: 1582, 2083: 1583, 2084: 1584, 2085: 1585, 2086: 1586, 2087: 1587, 2088: 1588, 2111: 1589, 2112: 1590, 2113: 1591, 2114: 1592, 2115: 1593, 2116: 1594, 2117: 1595, 2118: 1596, 2119: 1597, 2120: 1598, 2121: 1599, 2122: 1600, 2123: 1601, 2124: 1602, 2125: 1603, 2126: 1604, 2127: 1605, 2128: 1606, 2129: 1607, 2130: 1608, 2131: 1609, 2132: 1610, 2133: 1611, 2134: 1612, 2135: 1613, 2136: 1614, 2137: 1615, 2138: 1616, 2139: 1617, 2140: 1618, 2141: 1619, 2142: 1620, 2143: 1621, 2144: 1622, 2145: 1623, 2146: 1624, 2147: 1625, 2148: 1626, 2149: 1627, 2150: 1628, 2151: 1629, 2152: 1630, 2153: 1631, 2154: 1632, 2155: 1633, 2156: 1634, 2157: 1635, 2158: 1636, 2159: 1637, 2160: 1638, 2161: 1639, 2162: 1640, 2163: 1641, 2164: 1642, 2165: 1643, 2166: 1644, 2167: 1645, 2168: 1646, 2169: 1647, 2170: 1648, 2171: 1649, 2172: 1650, 2173: 1651, 2174: 1652, 2175: 1653, 2176: 1654, 2177: 1655, 2178: 1656, 2179: 1657, 2180: 1658, 2181: 1659, 2182: 1660, 2183: 1661, 2184: 1662, 2185: 1663, 2186: 1664, 2187: 1665, 2188: 1666, 2189: 1667, 2190: 1668, 2191: 1669, 2215: 1670, 2216: 1671, 2217: 1672, 2218: 1673, 2219: 1674, 2220: 1675, 2221: 1676, 2222: 1677, 2223: 1678, 2224: 1679, 2225: 1680, 2226: 1681, 2227: 1682, 2228: 1683, 2229: 1684, 2230: 1685, 2231: 1686, 2232: 1687, 2233: 1688, 2234: 1689, 2235: 1690, 2236: 1691, 2237: 1692, 2238: 1693, 2239: 1694, 2240: 1695, 2241: 1696, 2242: 1697, 2243: 1698, 2244: 1699, 2245: 1700, 2246: 1701, 2247: 1702, 2248: 1703, 2249: 1704, 2250: 1705, 2251: 1706, 2252: 1707, 2253: 1708, 2254: 1709, 2255: 1710, 2256: 1711, 2257: 1712, 2258: 1713, 2259: 1714, 2260: 1715, 2261: 1716, 2262: 1717, 2263: 1718, 2264: 1719, 2265: 1720, 2266: 1721, 2267: 1722, 2268: 1723, 2269: 1724, 2270: 1725, 2271: 1726, 2272: 1727, 2273: 1728, 2274: 1729, 2275: 1730, 2276: 1731, 2277: 1732, 2278: 1733, 2279: 1734, 2280: 1735, 2281: 1736, 2282: 1737, 2283: 1738, 2284: 1739, 2285: 1740, 2286: 1741, 2287: 1742, 2288: 1743, 2289: 1744, 2290: 1745, 2291: 1746, 2292: 1747, 2293: 1748, 2294: 1749, 2295: 1750, 2319: 1751, 2320: 1752, 2321: 1753, 2322: 1754, 2323: 1755, 2324: 1756, 2325: 1757, 2326: 1758, 2327: 1759, 2328: 1760, 2329: 1761, 2330: 1762, 2331: 1763, 2332: 1764, 2333: 1765, 2334: 1766, 2335: 1767, 2336: 1768, 2337: 1769, 2338: 1770, 2339: 1771, 2340: 1772, 2341: 1773, 2342: 1774, 2343: 1775, 2344: 1776, 2345: 1777, 2346: 1778, 2347: 1779, 2348: 1780, 2349: 1781, 2350: 1782, 2351: 1783, 2352: 1784, 2353: 1785, 2354: 1786, 2355: 1787, 2356: 1788, 2357: 1789, 2358: 1790, 2359: 1791, 2360: 1792, 2361: 1793, 2362: 1794, 2363: 1795, 2364: 1796, 2365: 1797, 2366: 1798, 2367: 1799, 2368: 1800, 2369: 1801, 2370: 1802, 2371: 1803, 2372: 1804, 2373: 1805, 2374: 1806, 2375: 1807, 2376: 1808, 2377: 1809, 2378: 1810, 2379: 1811, 2380: 1812, 2381: 1813, 2382: 1814, 2383: 1815, 2384: 1816, 2385: 1817, 2386: 1818, 2387: 1819, 2388: 1820, 2389: 1821, 2390: 1822, 2391: 1823, 2392: 1824, 2393: 1825, 2394: 1826, 2395: 1827, 2396: 1828, 2397: 1829, 2398: 1830, 2399: 1831, 2400: 1832, 2401: 1833, 2402: 1834, 2403: 1835, 2404: 1836, 2405: 1837, 2406: 1838, 2407: 1839, 2408: 1840, 2423: 1841, 2424: 1842, 2425: 1843, 2426: 1844, 2427: 1845, 2428: 1846, 2429: 1847, 2430: 1848, 2431: 1849, 2432: 1850, 2433: 1851, 2434: 1852, 2435: 1853, 2436: 1854, 2437: 1855, 2438: 1856, 2439: 1857, 2440: 1858, 2441: 1859, 2442: 1860, 2443: 1861, 2444: 1862, 2445: 1863, 2446: 1864, 2447: 1865, 2448: 1866, 2449: 1867, 2450: 1868, 2451: 1869, 2452: 1870, 2453: 1871, 2454: 1872, 2455: 1873, 2456: 1874, 2457: 1875, 2458: 1876, 2459: 1877, 2460: 1878, 2461: 1879, 2462: 1880, 2463: 1881, 2464: 1882, 2465: 1883, 2466: 1884, 2467: 1885, 2468: 1886, 2469: 1887, 2470: 1888, 2471: 1889, 2472: 1890, 2473: 1891, 2474: 1892, 2475: 1893, 2476: 1894, 2477: 1895, 2478: 1896, 2479: 1897, 2480: 1898, 2481: 1899, 2482: 1900, 2483: 1901, 2484: 1902, 2485: 1903, 2486: 1904, 2487: 1905, 2488: 1906, 2489: 1907, 2490: 1908, 2491: 1909, 2492: 1910, 2493: 1911, 2527: 1912, 2528: 1913, 2529: 1914, 2530: 1915, 2531: 1916, 2532: 1917, 2533: 1918, 2534: 1919, 2535: 1920, 2536: 1921, 2537: 1922, 2538: 1923, 2539: 1924, 2540: 1925, 2541: 1926, 2542: 1927, 2543: 1928, 2544: 1929, 2545: 1930, 2546: 1931, 2547: 1932, 2548: 1933, 2549: 1934, 2550: 1935, 2551: 1936, 2552: 1937, 2553: 1938, 2554: 1939, 2555: 1940, 2556: 1941, 2557: 1942, 2558: 1943, 2559: 1944, 2560: 1945, 2561: 1946, 2562: 1947, 2563: 1948, 2564: 1949, 2565: 1950, 2566: 1951, 2567: 1952, 2568: 1953, 2569: 1954, 2570: 1955, 2571: 1956, 2572: 1957, 2573: 1958, 2574: 1959, 2575: 1960, 2576: 1961, 2577: 1962, 2578: 1963, 2579: 1964, 2580: 1965, 2581: 1966, 2582: 1967, 2583: 1968, 2584: 1969, 2585: 1970, 2586: 1971, 2587: 1972, 2588: 1973, 2589: 1974, 2590: 1975, 2591: 1976, 2592: 1977, 2593: 1978, 2594: 1979, 2595: 1980, 2596: 1981, 2597: 1982, 2598: 1983, 2599: 1984, 2600: 1985, 2601: 1986, 2602: 1987, 2603: 1988, 2604: 1989, 2605: 1990, 2606: 1991, 2607: 1992, 2631: 1993, 2632: 1994, 2633: 1995, 2634: 1996, 2635: 1997, 2636: 1998, 2637: 1999, 2638: 2000, 2639: 2001, 2640: 2002, 2641: 2003, 2642: 2004, 2643: 2005, 2644: 2006, 2645: 2007, 2646: 2008, 2647: 2009, 2648: 2010, 2649: 2011, 2650: 2012, 2651: 2013, 2652: 2014, 2653: 2015, 2654: 2016, 2655: 2017, 2656: 2018, 2657: 2019, 2658: 2020, 2659: 2021, 2660: 2022, 2661: 2023}
After Remapping, max value of index 2 is 2023
** After Remapping **
**train**
The number of data is 63031
First data is ('000120a0-eee8-11ec-8b96-254279cd1714', [5, 5, 5, 5, 6, 1, 1, 1, 6, 7, 5, 5, 5, 5, 6, 1, 1, 1, 6, 7, 8, 7, 8, 8, 8, 6, 1, 6, 6, 1, 8, 7, 8, 8, 8, 6, 1, 6, 6, 1, 8, 8, 8, 8, 6, 1, 6, 8, 1, 7, 8, 7, 8, 8, 8, 8, 1, 6, 1, 1, 6], [351, 351, 352, 352, 353, 354, 355, 356, 357, 358, 359, 359, 360, 360, 361, 362, 363, 364, 365, 366, 375, 384, 376, 377, 378, 379, 380, 381, 382, 383, 490, 499, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 502, 503, 504, 505, 506, 507, 508, 509, 518, 510, 510, 511, 512, 513, 514, 515, 516, 517], [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])
**valid**
The number of data is 21077
First data is ('000ce720-e158-11ec-8870-5d4cb3b98715', [2, 1, 2, 3, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1], [37, 46, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 49, 50, 51, 52, 53, 54, 55], [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
**test**
The number of data is 20731
First data is ('00037820-bdf4-11ec-aad8-4fc760357a97', [1, 1, 1, 1, 1], [1, 2, 3, 4, 5], [1, 1, 1, 1, 1], [1, 1, 2, 2, 2])
Before splitted train length 63029, After splitted train length 2073202
Before splitted train length 63029, After splitted train length 2107260
Before splitted train length 63029, After splitted train length 2093470
Before splitted valid length 21077, After splitted valid length 704344
Before splitted valid length 21077, After splitted valid length 1382267
Before splitted valid length 21077, After splitted valid length 690735
