**train**
The number of data is 74915
First data is ('000120a0-eee8-11ec-8b96-254279cd1714', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8], [418, 418, 419, 419, 420, 421, 422, 423, 424, 425, 426, 435, 427, 428, 429, 430, 431, 432, 433, 434, 499, 508, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511, 511, 512, 513, 514, 515, 516, 517, 518, 527, 519, 519, 520, 521, 522, 523, 524, 525, 526], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
**valid**
The number of data is 25041
First data is ('000ce720-e158-11ec-8870-5d4cb3b98715', [4, 4, 5, 5, 3, 3, 3, 3, 3, 3], [131, 132, 133, 133, 134, 135, 136, 137, 138, 139], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
**test**
The number of data is 24782
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 9, 10, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [410, 410, 411, 411, 412, 413, 414, 415, 416, 417, 418, 418, 419, 419, 420, 421, 422, 423, 424, 425, 402, 402, 403, 403, 404, 405, 406, 407, 408, 409, 499, 508, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511, 511, 512, 513, 514, 515, 516, 517, 518, 527, 519, 519, 520, 521, 522, 523, 524, 525, 526, 594, 595, 596, 596, 597, 598, 599, 600, 601, 602, 603, 603, 612, 604, 604, 605, 606, 607, 608, 609, 610, 611, 613, 613, 614, 614, 615, 616, 617, 618, 619, 620, 621, 621, 622, 622, 623, 624, 625, 626, 627, 628, 683, 684, 685, 685, 686, 687, 688, 689, 690, 691, 692, 692, 693, 693, 694, 695, 696, 697, 698, 699, 700, 700, 701, 701, 702, 703, 704, 705, 706, 707, 772, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
Before Remapping, max value of problemid is 2378
After Remapping, max value of problemid is 1859
** After Remapping ProblemID **
**train**
The number of data is 74915
First data is ('000120a0-eee8-11ec-8b96-254279cd1714', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8], [322, 322, 323, 323, 324, 325, 326, 327, 328, 329, 330, 339, 331, 332, 333, 334, 335, 336, 337, 338, 392, 401, 393, 394, 395, 396, 397, 398, 399, 400, 402, 403, 404, 404, 405, 406, 407, 408, 409, 410, 411, 420, 412, 412, 413, 414, 415, 416, 417, 418, 419], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
**valid**
The number of data is 25041
First data is ('000ce720-e158-11ec-8870-5d4cb3b98715', [4, 4, 5, 5, 3, 3, 3, 3, 3, 3], [99, 100, 101, 101, 102, 103, 104, 105, 106, 107], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
**test**
The number of data is 24782
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 9, 10, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [314, 314, 315, 315, 316, 317, 318, 319, 320, 321, 322, 322, 323, 323, 324, 325, 326, 327, 328, 329, 306, 306, 307, 307, 308, 309, 310, 311, 312, 313, 392, 401, 393, 394, 395, 396, 397, 398, 399, 400, 402, 403, 404, 404, 405, 406, 407, 408, 409, 410, 411, 420, 412, 412, 413, 414, 415, 416, 417, 418, 419, 467, 468, 469, 469, 470, 471, 472, 473, 474, 475, 476, 476, 485, 477, 477, 478, 479, 480, 481, 482, 483, 484, 486, 486, 487, 487, 488, 489, 490, 491, 492, 493, 494, 494, 495, 495, 496, 497, 498, 499, 500, 501, 537, 538, 539, 539, 540, 541, 542, 543, 544, 545, 546, 546, 547, 547, 548, 549, 550, 551, 552, 553, 554, 554, 555, 555, 556, 557, 558, 559, 560, 561, 613, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 631, 632, 632, 633, 634, 635, 636, 637, 638, 631, 631, 632, 632, 633, 634, 635, 636, 637, 638, 631, 631, 632, 632, 633, 634, 635, 636, 637, 638], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
Before splitted train length 74915, After splitted train length 117766
Before splitted valid length 25041, After splitted valid length 39236
Before splitted test length 24782, After splitted test length 38704
Before splitted train length 74915, After splitted train length 117766
Before splitted valid length 25041, After splitted valid length 39236
Before splitted test length 24782, After splitted test length 38704
Before splitted train length 74915, After splitted train length 117766
Before splitted valid length 25041, After splitted valid length 39236
Before splitted test length 24782, After splitted test length 38704
Current time : 2023-08-09 14:31:46 KST, TensorFlow version :2.12.0
Current time : 2023-08-09 14:31:46 KST,  OS infromation :Linux
Current time : 2023-08-09 14:31:46 KST, OS version :#1 SMP Fri Jun 9 10:57:30 UTC 2023
Current time : 2023-08-09 14:31:46 KST,  Process information :x86_64
Current time : 2023-08-09 14:31:46 KST,  CPU_count :2
Current time : 2023-08-09 14:31:46 KST,  RAM_size :13(GB)
Successfully Load Previous Model, ./DKT/20230807results/model_weights.h5!
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 99)]         0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 99)]         0           []                               
                                                                                                  
 embedding (Embedding)          (None, 99, 8)        328         ['input_1[0][0]']                
                                                                                                  
 embedding_1 (Embedding)        (None, 99, 32)       59520       ['input_2[0][0]']                
                                                                                                  
 input_3 (InputLayer)           [(None, 99, 3)]      0           []                               
                                                                                                  
 concatenate (Concatenate)      (None, 99, 43)       0           ['embedding[0][0]',              
                                                                  'embedding_1[0][0]',            
                                                                  'input_3[0][0]']                
                                                                                                  
 lstm (LSTM)                    (None, 99, 64)       27648       ['concatenate[0][0]']            
                                                                                                  
 dense (Dense)                  (None, 99, 128)      8320        ['lstm[0][0]']                   
                                                                                                  
 batch_normalization (BatchNorm  (None, 99, 128)     512         ['dense[0][0]']                  
 alization)                                                                                       
                                                                                                  
 activation (Activation)        (None, 99, 128)      0           ['batch_normalization[0][0]']    
                                                                                                  
 dense_1 (Dense)                (None, 99, 41)       5289        ['activation[0][0]']             
                                                                                                  
 dense_2 (Dense)                (None, 99, 1860)     239940      ['activation[0][0]']             
                                                                                                  
 dense_3 (Dense)                (None, 99, 3)        387         ['activation[0][0]']             
                                                                                                  
==================================================================================================
Total params: 341,944
Trainable params: 341,688
Non-trainable params: 256
__________________________________________________________________________________________________
Epoch 1/100000
921/921 [==============================] - 130s 130ms/step - loss: 1.4504 - dense_1_loss: 0.2398 - dense_2_loss: 0.9627 - dense_3_loss: 0.2479 - dense_1_accuracy: 0.9423 - dense_2_accuracy: 0.8594 - dense_3_accuracy: 0.9011 - val_loss: 0.5114 - val_dense_1_loss: 0.0856 - val_dense_2_loss: 0.1929 - val_dense_3_loss: 0.2329 - val_dense_1_accuracy: 0.9760 - val_dense_2_accuracy: 0.9556 - val_dense_3_accuracy: 0.9035
Epoch 2/100000
921/921 [==============================] - 40s 43ms/step - loss: 0.4847 - dense_1_loss: 0.0813 - dense_2_loss: 0.1747 - dense_3_loss: 0.2286 - dense_1_accuracy: 0.9770 - dense_2_accuracy: 0.9570 - dense_3_accuracy: 0.9049 - val_loss: 0.4596 - val_dense_1_loss: 0.0754 - val_dense_2_loss: 0.1578 - val_dense_3_loss: 0.2264 - val_dense_1_accuracy: 0.9778 - val_dense_2_accuracy: 0.9592 - val_dense_3_accuracy: 0.9054
Epoch 3/100000
921/921 [==============================] - 27s 29ms/step - loss: 0.4552 - dense_1_loss: 0.0750 - dense_2_loss: 0.1544 - dense_3_loss: 0.2259 - dense_1_accuracy: 0.9776 - dense_2_accuracy: 0.9590 - dense_3_accuracy: 0.9053 - val_loss: 0.4441 - val_dense_1_loss: 0.0714 - val_dense_2_loss: 0.1464 - val_dense_3_loss: 0.2263 - val_dense_1_accuracy: 0.9782 - val_dense_2_accuracy: 0.9600 - val_dense_3_accuracy: 0.9053
Epoch 4/100000
921/921 [==============================] - 26s 28ms/step - loss: 0.4412 - dense_1_loss: 0.0717 - dense_2_loss: 0.1451 - dense_3_loss: 0.2244 - dense_1_accuracy: 0.9780 - dense_2_accuracy: 0.9602 - dense_3_accuracy: 0.9057 - val_loss: 0.4355 - val_dense_1_loss: 0.0697 - val_dense_2_loss: 0.1415 - val_dense_3_loss: 0.2242 - val_dense_1_accuracy: 0.9786 - val_dense_2_accuracy: 0.9612 - val_dense_3_accuracy: 0.9055
Epoch 5/100000
921/921 [==============================] - 22s 24ms/step - loss: 0.4330 - dense_1_loss: 0.0697 - dense_2_loss: 0.1400 - dense_3_loss: 0.2233 - dense_1_accuracy: 0.9783 - dense_2_accuracy: 0.9610 - dense_3_accuracy: 0.9060 - val_loss: 0.4276 - val_dense_1_loss: 0.0685 - val_dense_2_loss: 0.1369 - val_dense_3_loss: 0.2223 - val_dense_1_accuracy: 0.9785 - val_dense_2_accuracy: 0.9615 - val_dense_3_accuracy: 0.9063
Epoch 6/100000
921/921 [==============================] - 22s 24ms/step - loss: 0.4275 - dense_1_loss: 0.0683 - dense_2_loss: 0.1366 - dense_3_loss: 0.2225 - dense_1_accuracy: 0.9785 - dense_2_accuracy: 0.9615 - dense_3_accuracy: 0.9063 - val_loss: 0.4242 - val_dense_1_loss: 0.0674 - val_dense_2_loss: 0.1352 - val_dense_3_loss: 0.2216 - val_dense_1_accuracy: 0.9786 - val_dense_2_accuracy: 0.9618 - val_dense_3_accuracy: 0.9067
Epoch 7/100000
921/921 [==============================] - 25s 27ms/step - loss: 0.4239 - dense_1_loss: 0.0674 - dense_2_loss: 0.1345 - dense_3_loss: 0.2220 - dense_1_accuracy: 0.9787 - dense_2_accuracy: 0.9619 - dense_3_accuracy: 0.9065 - val_loss: 0.4199 - val_dense_1_loss: 0.0660 - val_dense_2_loss: 0.1326 - val_dense_3_loss: 0.2213 - val_dense_1_accuracy: 0.9791 - val_dense_2_accuracy: 0.9624 - val_dense_3_accuracy: 0.9066
Epoch 8/100000
921/921 [==============================] - 22s 23ms/step - loss: 0.4208 - dense_1_loss: 0.0666 - dense_2_loss: 0.1327 - dense_3_loss: 0.2215 - dense_1_accuracy: 0.9788 - dense_2_accuracy: 0.9622 - dense_3_accuracy: 0.9067 - val_loss: 0.4170 - val_dense_1_loss: 0.0653 - val_dense_2_loss: 0.1307 - val_dense_3_loss: 0.2209 - val_dense_1_accuracy: 0.9792 - val_dense_2_accuracy: 0.9627 - val_dense_3_accuracy: 0.9069
Epoch 9/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.4183 - dense_1_loss: 0.0660 - dense_2_loss: 0.1313 - dense_3_loss: 0.2211 - dense_1_accuracy: 0.9789 - dense_2_accuracy: 0.9624 - dense_3_accuracy: 0.9068 - val_loss: 0.4150 - val_dense_1_loss: 0.0648 - val_dense_2_loss: 0.1297 - val_dense_3_loss: 0.2205 - val_dense_1_accuracy: 0.9793 - val_dense_2_accuracy: 0.9629 - val_dense_3_accuracy: 0.9071
Epoch 10/100000
921/921 [==============================] - 22s 23ms/step - loss: 0.4164 - dense_1_loss: 0.0655 - dense_2_loss: 0.1301 - dense_3_loss: 0.2208 - dense_1_accuracy: 0.9790 - dense_2_accuracy: 0.9626 - dense_3_accuracy: 0.9069 - val_loss: 0.4136 - val_dense_1_loss: 0.0644 - val_dense_2_loss: 0.1287 - val_dense_3_loss: 0.2205 - val_dense_1_accuracy: 0.9795 - val_dense_2_accuracy: 0.9631 - val_dense_3_accuracy: 0.9070
Epoch 11/100000
921/921 [==============================] - 20s 22ms/step - loss: 0.4146 - dense_1_loss: 0.0651 - dense_2_loss: 0.1290 - dense_3_loss: 0.2205 - dense_1_accuracy: 0.9791 - dense_2_accuracy: 0.9629 - dense_3_accuracy: 0.9069 - val_loss: 0.4130 - val_dense_1_loss: 0.0645 - val_dense_2_loss: 0.1286 - val_dense_3_loss: 0.2199 - val_dense_1_accuracy: 0.9793 - val_dense_2_accuracy: 0.9629 - val_dense_3_accuracy: 0.9070
Epoch 12/100000
921/921 [==============================] - 20s 22ms/step - loss: 0.4132 - dense_1_loss: 0.0647 - dense_2_loss: 0.1282 - dense_3_loss: 0.2203 - dense_1_accuracy: 0.9792 - dense_2_accuracy: 0.9630 - dense_3_accuracy: 0.9070 - val_loss: 0.4159 - val_dense_1_loss: 0.0650 - val_dense_2_loss: 0.1298 - val_dense_3_loss: 0.2211 - val_dense_1_accuracy: 0.9792 - val_dense_2_accuracy: 0.9628 - val_dense_3_accuracy: 0.9062
Epoch 13/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.4120 - dense_1_loss: 0.0644 - dense_2_loss: 0.1275 - dense_3_loss: 0.2201 - dense_1_accuracy: 0.9792 - dense_2_accuracy: 0.9631 - dense_3_accuracy: 0.9071 - val_loss: 0.4109 - val_dense_1_loss: 0.0639 - val_dense_2_loss: 0.1272 - val_dense_3_loss: 0.2198 - val_dense_1_accuracy: 0.9796 - val_dense_2_accuracy: 0.9634 - val_dense_3_accuracy: 0.9072
Epoch 14/100000
921/921 [==============================] - 20s 22ms/step - loss: 0.4109 - dense_1_loss: 0.0642 - dense_2_loss: 0.1268 - dense_3_loss: 0.2199 - dense_1_accuracy: 0.9793 - dense_2_accuracy: 0.9632 - dense_3_accuracy: 0.9071 - val_loss: 0.4079 - val_dense_1_loss: 0.0633 - val_dense_2_loss: 0.1255 - val_dense_3_loss: 0.2191 - val_dense_1_accuracy: 0.9796 - val_dense_2_accuracy: 0.9636 - val_dense_3_accuracy: 0.9075
Epoch 15/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.4098 - dense_1_loss: 0.0639 - dense_2_loss: 0.1263 - dense_3_loss: 0.2197 - dense_1_accuracy: 0.9793 - dense_2_accuracy: 0.9633 - dense_3_accuracy: 0.9072 - val_loss: 0.4086 - val_dense_1_loss: 0.0631 - val_dense_2_loss: 0.1250 - val_dense_3_loss: 0.2205 - val_dense_1_accuracy: 0.9796 - val_dense_2_accuracy: 0.9637 - val_dense_3_accuracy: 0.9066
Epoch 16/100000
921/921 [==============================] - 20s 21ms/step - loss: 0.4089 - dense_1_loss: 0.0637 - dense_2_loss: 0.1257 - dense_3_loss: 0.2196 - dense_1_accuracy: 0.9794 - dense_2_accuracy: 0.9634 - dense_3_accuracy: 0.9072 - val_loss: 0.4065 - val_dense_1_loss: 0.0629 - val_dense_2_loss: 0.1246 - val_dense_3_loss: 0.2190 - val_dense_1_accuracy: 0.9797 - val_dense_2_accuracy: 0.9637 - val_dense_3_accuracy: 0.9075
Epoch 17/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.4082 - dense_1_loss: 0.0635 - dense_2_loss: 0.1252 - dense_3_loss: 0.2195 - dense_1_accuracy: 0.9794 - dense_2_accuracy: 0.9635 - dense_3_accuracy: 0.9073 - val_loss: 0.4077 - val_dense_1_loss: 0.0634 - val_dense_2_loss: 0.1254 - val_dense_3_loss: 0.2189 - val_dense_1_accuracy: 0.9793 - val_dense_2_accuracy: 0.9635 - val_dense_3_accuracy: 0.9075
Epoch 18/100000
921/921 [==============================] - 20s 22ms/step - loss: 0.4074 - dense_1_loss: 0.0633 - dense_2_loss: 0.1248 - dense_3_loss: 0.2193 - dense_1_accuracy: 0.9794 - dense_2_accuracy: 0.9636 - dense_3_accuracy: 0.9073 - val_loss: 0.4056 - val_dense_1_loss: 0.0628 - val_dense_2_loss: 0.1239 - val_dense_3_loss: 0.2188 - val_dense_1_accuracy: 0.9796 - val_dense_2_accuracy: 0.9639 - val_dense_3_accuracy: 0.9075
Epoch 19/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.4067 - dense_1_loss: 0.0632 - dense_2_loss: 0.1243 - dense_3_loss: 0.2192 - dense_1_accuracy: 0.9795 - dense_2_accuracy: 0.9637 - dense_3_accuracy: 0.9073 - val_loss: 0.4050 - val_dense_1_loss: 0.0626 - val_dense_2_loss: 0.1237 - val_dense_3_loss: 0.2187 - val_dense_1_accuracy: 0.9797 - val_dense_2_accuracy: 0.9640 - val_dense_3_accuracy: 0.9075
Epoch 20/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.4061 - dense_1_loss: 0.0630 - dense_2_loss: 0.1240 - dense_3_loss: 0.2192 - dense_1_accuracy: 0.9795 - dense_2_accuracy: 0.9637 - dense_3_accuracy: 0.9074 - val_loss: 0.4048 - val_dense_1_loss: 0.0625 - val_dense_2_loss: 0.1236 - val_dense_3_loss: 0.2187 - val_dense_1_accuracy: 0.9798 - val_dense_2_accuracy: 0.9640 - val_dense_3_accuracy: 0.9077
Epoch 21/100000
921/921 [==============================] - 25s 27ms/step - loss: 0.4056 - dense_1_loss: 0.0629 - dense_2_loss: 0.1237 - dense_3_loss: 0.2190 - dense_1_accuracy: 0.9795 - dense_2_accuracy: 0.9638 - dense_3_accuracy: 0.9074 - val_loss: 0.4038 - val_dense_1_loss: 0.0622 - val_dense_2_loss: 0.1231 - val_dense_3_loss: 0.2185 - val_dense_1_accuracy: 0.9798 - val_dense_2_accuracy: 0.9640 - val_dense_3_accuracy: 0.9076
Epoch 22/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.4050 - dense_1_loss: 0.0627 - dense_2_loss: 0.1233 - dense_3_loss: 0.2190 - dense_1_accuracy: 0.9796 - dense_2_accuracy: 0.9639 - dense_3_accuracy: 0.9075 - val_loss: 0.4064 - val_dense_1_loss: 0.0625 - val_dense_2_loss: 0.1231 - val_dense_3_loss: 0.2208 - val_dense_1_accuracy: 0.9797 - val_dense_2_accuracy: 0.9640 - val_dense_3_accuracy: 0.9066
Epoch 23/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.4048 - dense_1_loss: 0.0627 - dense_2_loss: 0.1232 - dense_3_loss: 0.2189 - dense_1_accuracy: 0.9796 - dense_2_accuracy: 0.9639 - dense_3_accuracy: 0.9074 - val_loss: 0.4048 - val_dense_1_loss: 0.0624 - val_dense_2_loss: 0.1232 - val_dense_3_loss: 0.2192 - val_dense_1_accuracy: 0.9798 - val_dense_2_accuracy: 0.9642 - val_dense_3_accuracy: 0.9070
Epoch 24/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.4040 - dense_1_loss: 0.0625 - dense_2_loss: 0.1228 - dense_3_loss: 0.2188 - dense_1_accuracy: 0.9796 - dense_2_accuracy: 0.9640 - dense_3_accuracy: 0.9075 - val_loss: 0.4038 - val_dense_1_loss: 0.0620 - val_dense_2_loss: 0.1223 - val_dense_3_loss: 0.2195 - val_dense_1_accuracy: 0.9798 - val_dense_2_accuracy: 0.9643 - val_dense_3_accuracy: 0.9070
Epoch 25/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.4036 - dense_1_loss: 0.0624 - dense_2_loss: 0.1225 - dense_3_loss: 0.2188 - dense_1_accuracy: 0.9796 - dense_2_accuracy: 0.9640 - dense_3_accuracy: 0.9075 - val_loss: 0.4025 - val_dense_1_loss: 0.0619 - val_dense_2_loss: 0.1223 - val_dense_3_loss: 0.2183 - val_dense_1_accuracy: 0.9799 - val_dense_2_accuracy: 0.9643 - val_dense_3_accuracy: 0.9078
Epoch 26/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.4034 - dense_1_loss: 0.0623 - dense_2_loss: 0.1223 - dense_3_loss: 0.2187 - dense_1_accuracy: 0.9796 - dense_2_accuracy: 0.9640 - dense_3_accuracy: 0.9075 - val_loss: 0.4020 - val_dense_1_loss: 0.0617 - val_dense_2_loss: 0.1220 - val_dense_3_loss: 0.2182 - val_dense_1_accuracy: 0.9799 - val_dense_2_accuracy: 0.9643 - val_dense_3_accuracy: 0.9077
Epoch 27/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.4029 - dense_1_loss: 0.0622 - dense_2_loss: 0.1220 - dense_3_loss: 0.2186 - dense_1_accuracy: 0.9797 - dense_2_accuracy: 0.9641 - dense_3_accuracy: 0.9075 - val_loss: 0.4016 - val_dense_1_loss: 0.0618 - val_dense_2_loss: 0.1217 - val_dense_3_loss: 0.2182 - val_dense_1_accuracy: 0.9798 - val_dense_2_accuracy: 0.9643 - val_dense_3_accuracy: 0.9078
Epoch 28/100000
921/921 [==============================] - 22s 23ms/step - loss: 0.4025 - dense_1_loss: 0.0621 - dense_2_loss: 0.1218 - dense_3_loss: 0.2186 - dense_1_accuracy: 0.9797 - dense_2_accuracy: 0.9642 - dense_3_accuracy: 0.9075 - val_loss: 0.4020 - val_dense_1_loss: 0.0619 - val_dense_2_loss: 0.1219 - val_dense_3_loss: 0.2182 - val_dense_1_accuracy: 0.9799 - val_dense_2_accuracy: 0.9643 - val_dense_3_accuracy: 0.9077
Epoch 29/100000
921/921 [==============================] - 20s 22ms/step - loss: 0.4021 - dense_1_loss: 0.0621 - dense_2_loss: 0.1216 - dense_3_loss: 0.2185 - dense_1_accuracy: 0.9797 - dense_2_accuracy: 0.9642 - dense_3_accuracy: 0.9076 - val_loss: 0.4018 - val_dense_1_loss: 0.0617 - val_dense_2_loss: 0.1216 - val_dense_3_loss: 0.2185 - val_dense_1_accuracy: 0.9800 - val_dense_2_accuracy: 0.9644 - val_dense_3_accuracy: 0.9074
Epoch 30/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.4018 - dense_1_loss: 0.0620 - dense_2_loss: 0.1214 - dense_3_loss: 0.2185 - dense_1_accuracy: 0.9797 - dense_2_accuracy: 0.9642 - dense_3_accuracy: 0.9075 - val_loss: 0.4010 - val_dense_1_loss: 0.0617 - val_dense_2_loss: 0.1214 - val_dense_3_loss: 0.2180 - val_dense_1_accuracy: 0.9799 - val_dense_2_accuracy: 0.9644 - val_dense_3_accuracy: 0.9077
Epoch 31/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.4015 - dense_1_loss: 0.0619 - dense_2_loss: 0.1212 - dense_3_loss: 0.2184 - dense_1_accuracy: 0.9798 - dense_2_accuracy: 0.9643 - dense_3_accuracy: 0.9076 - val_loss: 0.4009 - val_dense_1_loss: 0.0616 - val_dense_2_loss: 0.1212 - val_dense_3_loss: 0.2182 - val_dense_1_accuracy: 0.9799 - val_dense_2_accuracy: 0.9645 - val_dense_3_accuracy: 0.9077
Epoch 32/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.4013 - dense_1_loss: 0.0618 - dense_2_loss: 0.1211 - dense_3_loss: 0.2184 - dense_1_accuracy: 0.9798 - dense_2_accuracy: 0.9643 - dense_3_accuracy: 0.9076 - val_loss: 0.4004 - val_dense_1_loss: 0.0615 - val_dense_2_loss: 0.1209 - val_dense_3_loss: 0.2181 - val_dense_1_accuracy: 0.9800 - val_dense_2_accuracy: 0.9646 - val_dense_3_accuracy: 0.9077
Epoch 33/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.4009 - dense_1_loss: 0.0617 - dense_2_loss: 0.1208 - dense_3_loss: 0.2183 - dense_1_accuracy: 0.9798 - dense_2_accuracy: 0.9644 - dense_3_accuracy: 0.9076 - val_loss: 0.4000 - val_dense_1_loss: 0.0614 - val_dense_2_loss: 0.1208 - val_dense_3_loss: 0.2179 - val_dense_1_accuracy: 0.9799 - val_dense_2_accuracy: 0.9645 - val_dense_3_accuracy: 0.9078
Epoch 34/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.4006 - dense_1_loss: 0.0617 - dense_2_loss: 0.1207 - dense_3_loss: 0.2182 - dense_1_accuracy: 0.9798 - dense_2_accuracy: 0.9644 - dense_3_accuracy: 0.9076 - val_loss: 0.4014 - val_dense_1_loss: 0.0617 - val_dense_2_loss: 0.1216 - val_dense_3_loss: 0.2180 - val_dense_1_accuracy: 0.9799 - val_dense_2_accuracy: 0.9645 - val_dense_3_accuracy: 0.9078
Epoch 35/100000
921/921 [==============================] - 20s 22ms/step - loss: 0.4004 - dense_1_loss: 0.0616 - dense_2_loss: 0.1205 - dense_3_loss: 0.2183 - dense_1_accuracy: 0.9798 - dense_2_accuracy: 0.9644 - dense_3_accuracy: 0.9076 - val_loss: 0.4001 - val_dense_1_loss: 0.0614 - val_dense_2_loss: 0.1206 - val_dense_3_loss: 0.2181 - val_dense_1_accuracy: 0.9800 - val_dense_2_accuracy: 0.9646 - val_dense_3_accuracy: 0.9077
Epoch 36/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.4001 - dense_1_loss: 0.0615 - dense_2_loss: 0.1204 - dense_3_loss: 0.2182 - dense_1_accuracy: 0.9798 - dense_2_accuracy: 0.9645 - dense_3_accuracy: 0.9076 - val_loss: 0.4007 - val_dense_1_loss: 0.0616 - val_dense_2_loss: 0.1212 - val_dense_3_loss: 0.2180 - val_dense_1_accuracy: 0.9799 - val_dense_2_accuracy: 0.9644 - val_dense_3_accuracy: 0.9078
Epoch 37/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3998 - dense_1_loss: 0.0615 - dense_2_loss: 0.1202 - dense_3_loss: 0.2181 - dense_1_accuracy: 0.9799 - dense_2_accuracy: 0.9645 - dense_3_accuracy: 0.9077 - val_loss: 0.4003 - val_dense_1_loss: 0.0614 - val_dense_2_loss: 0.1207 - val_dense_3_loss: 0.2183 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9646 - val_dense_3_accuracy: 0.9076
Epoch 38/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3997 - dense_1_loss: 0.0614 - dense_2_loss: 0.1201 - dense_3_loss: 0.2181 - dense_1_accuracy: 0.9799 - dense_2_accuracy: 0.9645 - dense_3_accuracy: 0.9077 - val_loss: 0.3997 - val_dense_1_loss: 0.0614 - val_dense_2_loss: 0.1206 - val_dense_3_loss: 0.2177 - val_dense_1_accuracy: 0.9800 - val_dense_2_accuracy: 0.9646 - val_dense_3_accuracy: 0.9078
Epoch 39/100000
921/921 [==============================] - 26s 28ms/step - loss: 0.3994 - dense_1_loss: 0.0614 - dense_2_loss: 0.1199 - dense_3_loss: 0.2181 - dense_1_accuracy: 0.9799 - dense_2_accuracy: 0.9646 - dense_3_accuracy: 0.9077 - val_loss: 0.3994 - val_dense_1_loss: 0.0612 - val_dense_2_loss: 0.1203 - val_dense_3_loss: 0.2179 - val_dense_1_accuracy: 0.9800 - val_dense_2_accuracy: 0.9647 - val_dense_3_accuracy: 0.9078
Epoch 40/100000
921/921 [==============================] - 22s 24ms/step - loss: 0.3992 - dense_1_loss: 0.0613 - dense_2_loss: 0.1198 - dense_3_loss: 0.2180 - dense_1_accuracy: 0.9799 - dense_2_accuracy: 0.9646 - dense_3_accuracy: 0.9077 - val_loss: 0.3991 - val_dense_1_loss: 0.0612 - val_dense_2_loss: 0.1202 - val_dense_3_loss: 0.2176 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9647 - val_dense_3_accuracy: 0.9079
Epoch 41/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3990 - dense_1_loss: 0.0613 - dense_2_loss: 0.1197 - dense_3_loss: 0.2180 - dense_1_accuracy: 0.9799 - dense_2_accuracy: 0.9646 - dense_3_accuracy: 0.9077 - val_loss: 0.3990 - val_dense_1_loss: 0.0611 - val_dense_2_loss: 0.1201 - val_dense_3_loss: 0.2177 - val_dense_1_accuracy: 0.9800 - val_dense_2_accuracy: 0.9648 - val_dense_3_accuracy: 0.9078
Epoch 42/100000
921/921 [==============================] - 25s 28ms/step - loss: 0.3988 - dense_1_loss: 0.0613 - dense_2_loss: 0.1196 - dense_3_loss: 0.2179 - dense_1_accuracy: 0.9799 - dense_2_accuracy: 0.9646 - dense_3_accuracy: 0.9077 - val_loss: 0.3993 - val_dense_1_loss: 0.0611 - val_dense_2_loss: 0.1200 - val_dense_3_loss: 0.2181 - val_dense_1_accuracy: 0.9800 - val_dense_2_accuracy: 0.9647 - val_dense_3_accuracy: 0.9077
Epoch 43/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.3985 - dense_1_loss: 0.0612 - dense_2_loss: 0.1194 - dense_3_loss: 0.2179 - dense_1_accuracy: 0.9799 - dense_2_accuracy: 0.9646 - dense_3_accuracy: 0.9077 - val_loss: 0.3989 - val_dense_1_loss: 0.0610 - val_dense_2_loss: 0.1199 - val_dense_3_loss: 0.2180 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9648 - val_dense_3_accuracy: 0.9078
Epoch 44/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.3984 - dense_1_loss: 0.0612 - dense_2_loss: 0.1193 - dense_3_loss: 0.2179 - dense_1_accuracy: 0.9799 - dense_2_accuracy: 0.9647 - dense_3_accuracy: 0.9077 - val_loss: 0.3987 - val_dense_1_loss: 0.0611 - val_dense_2_loss: 0.1200 - val_dense_3_loss: 0.2176 - val_dense_1_accuracy: 0.9800 - val_dense_2_accuracy: 0.9647 - val_dense_3_accuracy: 0.9079
Epoch 45/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3983 - dense_1_loss: 0.0611 - dense_2_loss: 0.1193 - dense_3_loss: 0.2178 - dense_1_accuracy: 0.9799 - dense_2_accuracy: 0.9647 - dense_3_accuracy: 0.9077 - val_loss: 0.3994 - val_dense_1_loss: 0.0611 - val_dense_2_loss: 0.1199 - val_dense_3_loss: 0.2185 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9647 - val_dense_3_accuracy: 0.9076
Epoch 46/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.3980 - dense_1_loss: 0.0610 - dense_2_loss: 0.1191 - dense_3_loss: 0.2178 - dense_1_accuracy: 0.9799 - dense_2_accuracy: 0.9647 - dense_3_accuracy: 0.9078 - val_loss: 0.3984 - val_dense_1_loss: 0.0611 - val_dense_2_loss: 0.1198 - val_dense_3_loss: 0.2176 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9648 - val_dense_3_accuracy: 0.9079
Epoch 47/100000
921/921 [==============================] - 27s 29ms/step - loss: 0.3977 - dense_1_loss: 0.0610 - dense_2_loss: 0.1189 - dense_3_loss: 0.2178 - dense_1_accuracy: 0.9800 - dense_2_accuracy: 0.9647 - dense_3_accuracy: 0.9078 - val_loss: 0.3985 - val_dense_1_loss: 0.0611 - val_dense_2_loss: 0.1198 - val_dense_3_loss: 0.2176 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9648 - val_dense_3_accuracy: 0.9078
Epoch 48/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3975 - dense_1_loss: 0.0609 - dense_2_loss: 0.1188 - dense_3_loss: 0.2178 - dense_1_accuracy: 0.9800 - dense_2_accuracy: 0.9648 - dense_3_accuracy: 0.9078 - val_loss: 0.3987 - val_dense_1_loss: 0.0610 - val_dense_2_loss: 0.1196 - val_dense_3_loss: 0.2181 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9648 - val_dense_3_accuracy: 0.9077
Epoch 49/100000
921/921 [==============================] - 22s 23ms/step - loss: 0.3975 - dense_1_loss: 0.0609 - dense_2_loss: 0.1188 - dense_3_loss: 0.2177 - dense_1_accuracy: 0.9800 - dense_2_accuracy: 0.9648 - dense_3_accuracy: 0.9078 - val_loss: 0.3980 - val_dense_1_loss: 0.0609 - val_dense_2_loss: 0.1194 - val_dense_3_loss: 0.2178 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9649 - val_dense_3_accuracy: 0.9079
Epoch 50/100000
921/921 [==============================] - 22s 24ms/step - loss: 0.3973 - dense_1_loss: 0.0609 - dense_2_loss: 0.1187 - dense_3_loss: 0.2177 - dense_1_accuracy: 0.9800 - dense_2_accuracy: 0.9648 - dense_3_accuracy: 0.9078 - val_loss: 0.3980 - val_dense_1_loss: 0.0609 - val_dense_2_loss: 0.1195 - val_dense_3_loss: 0.2176 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9649 - val_dense_3_accuracy: 0.9079
Epoch 51/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.3971 - dense_1_loss: 0.0608 - dense_2_loss: 0.1186 - dense_3_loss: 0.2177 - dense_1_accuracy: 0.9800 - dense_2_accuracy: 0.9648 - dense_3_accuracy: 0.9078 - val_loss: 0.3980 - val_dense_1_loss: 0.0610 - val_dense_2_loss: 0.1196 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9800 - val_dense_2_accuracy: 0.9648 - val_dense_3_accuracy: 0.9080
Epoch 52/100000
921/921 [==============================] - 29s 31ms/step - loss: 0.3970 - dense_1_loss: 0.0608 - dense_2_loss: 0.1185 - dense_3_loss: 0.2177 - dense_1_accuracy: 0.9800 - dense_2_accuracy: 0.9649 - dense_3_accuracy: 0.9078 - val_loss: 0.3979 - val_dense_1_loss: 0.0609 - val_dense_2_loss: 0.1194 - val_dense_3_loss: 0.2176 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9649 - val_dense_3_accuracy: 0.9079
Epoch 53/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3968 - dense_1_loss: 0.0607 - dense_2_loss: 0.1184 - dense_3_loss: 0.2176 - dense_1_accuracy: 0.9800 - dense_2_accuracy: 0.9649 - dense_3_accuracy: 0.9078 - val_loss: 0.3976 - val_dense_1_loss: 0.0609 - val_dense_2_loss: 0.1193 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9649 - val_dense_3_accuracy: 0.9079
Epoch 54/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.3967 - dense_1_loss: 0.0607 - dense_2_loss: 0.1183 - dense_3_loss: 0.2176 - dense_1_accuracy: 0.9800 - dense_2_accuracy: 0.9649 - dense_3_accuracy: 0.9078 - val_loss: 0.3977 - val_dense_1_loss: 0.0609 - val_dense_2_loss: 0.1193 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9650 - val_dense_3_accuracy: 0.9080
Epoch 55/100000
921/921 [==============================] - 25s 28ms/step - loss: 0.3965 - dense_1_loss: 0.0607 - dense_2_loss: 0.1182 - dense_3_loss: 0.2176 - dense_1_accuracy: 0.9800 - dense_2_accuracy: 0.9649 - dense_3_accuracy: 0.9078 - val_loss: 0.3984 - val_dense_1_loss: 0.0612 - val_dense_2_loss: 0.1195 - val_dense_3_loss: 0.2176 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9649 - val_dense_3_accuracy: 0.9080
Epoch 56/100000
921/921 [==============================] - 23s 24ms/step - loss: 0.3964 - dense_1_loss: 0.0607 - dense_2_loss: 0.1181 - dense_3_loss: 0.2176 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9649 - dense_3_accuracy: 0.9078 - val_loss: 0.3976 - val_dense_1_loss: 0.0607 - val_dense_2_loss: 0.1191 - val_dense_3_loss: 0.2178 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9650 - val_dense_3_accuracy: 0.9079
Epoch 57/100000
921/921 [==============================] - 22s 24ms/step - loss: 0.3963 - dense_1_loss: 0.0606 - dense_2_loss: 0.1181 - dense_3_loss: 0.2176 - dense_1_accuracy: 0.9800 - dense_2_accuracy: 0.9650 - dense_3_accuracy: 0.9078 - val_loss: 0.3979 - val_dense_1_loss: 0.0609 - val_dense_2_loss: 0.1194 - val_dense_3_loss: 0.2176 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9650 - val_dense_3_accuracy: 0.9078
Epoch 58/100000
921/921 [==============================] - 28s 30ms/step - loss: 0.3961 - dense_1_loss: 0.0606 - dense_2_loss: 0.1180 - dense_3_loss: 0.2175 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9650 - dense_3_accuracy: 0.9078 - val_loss: 0.3973 - val_dense_1_loss: 0.0608 - val_dense_2_loss: 0.1191 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9650 - val_dense_3_accuracy: 0.9079
Epoch 59/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3961 - dense_1_loss: 0.0606 - dense_2_loss: 0.1179 - dense_3_loss: 0.2175 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9650 - dense_3_accuracy: 0.9078 - val_loss: 0.3969 - val_dense_1_loss: 0.0607 - val_dense_2_loss: 0.1189 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9651 - val_dense_3_accuracy: 0.9080
Epoch 60/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3958 - dense_1_loss: 0.0605 - dense_2_loss: 0.1178 - dense_3_loss: 0.2175 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9650 - dense_3_accuracy: 0.9078 - val_loss: 0.3969 - val_dense_1_loss: 0.0607 - val_dense_2_loss: 0.1189 - val_dense_3_loss: 0.2173 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9650 - val_dense_3_accuracy: 0.9080
Epoch 61/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3957 - dense_1_loss: 0.0605 - dense_2_loss: 0.1177 - dense_3_loss: 0.2175 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9650 - dense_3_accuracy: 0.9079 - val_loss: 0.3971 - val_dense_1_loss: 0.0608 - val_dense_2_loss: 0.1190 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9650 - val_dense_3_accuracy: 0.9080
Epoch 62/100000
921/921 [==============================] - 22s 24ms/step - loss: 0.3956 - dense_1_loss: 0.0605 - dense_2_loss: 0.1177 - dense_3_loss: 0.2174 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9650 - dense_3_accuracy: 0.9079 - val_loss: 0.3968 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1188 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9650 - val_dense_3_accuracy: 0.9080
Epoch 63/100000
921/921 [==============================] - 25s 27ms/step - loss: 0.3955 - dense_1_loss: 0.0604 - dense_2_loss: 0.1176 - dense_3_loss: 0.2175 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9651 - dense_3_accuracy: 0.9079 - val_loss: 0.3972 - val_dense_1_loss: 0.0608 - val_dense_2_loss: 0.1189 - val_dense_3_loss: 0.2176 - val_dense_1_accuracy: 0.9801 - val_dense_2_accuracy: 0.9650 - val_dense_3_accuracy: 0.9080
Epoch 64/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3953 - dense_1_loss: 0.0604 - dense_2_loss: 0.1175 - dense_3_loss: 0.2174 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9651 - dense_3_accuracy: 0.9079 - val_loss: 0.3970 - val_dense_1_loss: 0.0607 - val_dense_2_loss: 0.1189 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9651 - val_dense_3_accuracy: 0.9080
Epoch 65/100000
921/921 [==============================] - 22s 23ms/step - loss: 0.3953 - dense_1_loss: 0.0604 - dense_2_loss: 0.1174 - dense_3_loss: 0.2174 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9651 - dense_3_accuracy: 0.9079 - val_loss: 0.3968 - val_dense_1_loss: 0.0607 - val_dense_2_loss: 0.1187 - val_dense_3_loss: 0.2173 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9651 - val_dense_3_accuracy: 0.9080
Epoch 66/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3951 - dense_1_loss: 0.0604 - dense_2_loss: 0.1174 - dense_3_loss: 0.2174 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9651 - dense_3_accuracy: 0.9079 - val_loss: 0.3967 - val_dense_1_loss: 0.0607 - val_dense_2_loss: 0.1188 - val_dense_3_loss: 0.2172 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9651 - val_dense_3_accuracy: 0.9080
Epoch 67/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.3950 - dense_1_loss: 0.0603 - dense_2_loss: 0.1173 - dense_3_loss: 0.2174 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9651 - dense_3_accuracy: 0.9079 - val_loss: 0.3965 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1187 - val_dense_3_loss: 0.2172 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9651 - val_dense_3_accuracy: 0.9081
Epoch 68/100000
921/921 [==============================] - 26s 29ms/step - loss: 0.3949 - dense_1_loss: 0.0603 - dense_2_loss: 0.1172 - dense_3_loss: 0.2174 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9652 - dense_3_accuracy: 0.9079 - val_loss: 0.3970 - val_dense_1_loss: 0.0607 - val_dense_2_loss: 0.1188 - val_dense_3_loss: 0.2175 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9651 - val_dense_3_accuracy: 0.9079
Epoch 69/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3948 - dense_1_loss: 0.0603 - dense_2_loss: 0.1172 - dense_3_loss: 0.2173 - dense_1_accuracy: 0.9801 - dense_2_accuracy: 0.9651 - dense_3_accuracy: 0.9079 - val_loss: 0.3967 - val_dense_1_loss: 0.0608 - val_dense_2_loss: 0.1188 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9651 - val_dense_3_accuracy: 0.9081
Epoch 70/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3947 - dense_1_loss: 0.0602 - dense_2_loss: 0.1171 - dense_3_loss: 0.2173 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9652 - dense_3_accuracy: 0.9079 - val_loss: 0.3964 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1187 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9651 - val_dense_3_accuracy: 0.9080
Epoch 71/100000
921/921 [==============================] - 22s 23ms/step - loss: 0.3946 - dense_1_loss: 0.0602 - dense_2_loss: 0.1171 - dense_3_loss: 0.2173 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9652 - dense_3_accuracy: 0.9079 - val_loss: 0.3963 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1185 - val_dense_3_loss: 0.2173 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9080
Epoch 72/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3945 - dense_1_loss: 0.0602 - dense_2_loss: 0.1170 - dense_3_loss: 0.2173 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9652 - dense_3_accuracy: 0.9079 - val_loss: 0.3963 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1185 - val_dense_3_loss: 0.2173 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9080
Epoch 73/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3944 - dense_1_loss: 0.0602 - dense_2_loss: 0.1169 - dense_3_loss: 0.2173 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9653 - dense_3_accuracy: 0.9079 - val_loss: 0.3964 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1185 - val_dense_3_loss: 0.2172 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9651 - val_dense_3_accuracy: 0.9081
Epoch 74/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3943 - dense_1_loss: 0.0602 - dense_2_loss: 0.1169 - dense_3_loss: 0.2172 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9652 - dense_3_accuracy: 0.9079 - val_loss: 0.3970 - val_dense_1_loss: 0.0607 - val_dense_2_loss: 0.1188 - val_dense_3_loss: 0.2176 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9651 - val_dense_3_accuracy: 0.9078
Epoch 75/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3941 - dense_1_loss: 0.0601 - dense_2_loss: 0.1168 - dense_3_loss: 0.2172 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9652 - dense_3_accuracy: 0.9079 - val_loss: 0.3964 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1185 - val_dense_3_loss: 0.2173 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9651 - val_dense_3_accuracy: 0.9080
Epoch 76/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3941 - dense_1_loss: 0.0601 - dense_2_loss: 0.1168 - dense_3_loss: 0.2172 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9653 - dense_3_accuracy: 0.9079 - val_loss: 0.3963 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1185 - val_dense_3_loss: 0.2172 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9080
Epoch 77/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3940 - dense_1_loss: 0.0601 - dense_2_loss: 0.1167 - dense_3_loss: 0.2172 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9653 - dense_3_accuracy: 0.9079 - val_loss: 0.3966 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1186 - val_dense_3_loss: 0.2173 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9080
Epoch 78/100000
921/921 [==============================] - 22s 24ms/step - loss: 0.3940 - dense_1_loss: 0.0601 - dense_2_loss: 0.1167 - dense_3_loss: 0.2172 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9653 - dense_3_accuracy: 0.9079 - val_loss: 0.3962 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1185 - val_dense_3_loss: 0.2172 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9081
Epoch 79/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3939 - dense_1_loss: 0.0601 - dense_2_loss: 0.1166 - dense_3_loss: 0.2172 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9653 - dense_3_accuracy: 0.9080 - val_loss: 0.3963 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1184 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9080
Epoch 80/100000
921/921 [==============================] - 25s 28ms/step - loss: 0.3937 - dense_1_loss: 0.0600 - dense_2_loss: 0.1165 - dense_3_loss: 0.2172 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9653 - dense_3_accuracy: 0.9080 - val_loss: 0.3969 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1184 - val_dense_3_loss: 0.2181 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9075
Epoch 81/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3936 - dense_1_loss: 0.0600 - dense_2_loss: 0.1165 - dense_3_loss: 0.2171 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9654 - dense_3_accuracy: 0.9079 - val_loss: 0.3958 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1182 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9081
Epoch 82/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3935 - dense_1_loss: 0.0600 - dense_2_loss: 0.1164 - dense_3_loss: 0.2171 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9653 - dense_3_accuracy: 0.9080 - val_loss: 0.3959 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1181 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9080
Epoch 83/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3934 - dense_1_loss: 0.0599 - dense_2_loss: 0.1163 - dense_3_loss: 0.2171 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9654 - dense_3_accuracy: 0.9079 - val_loss: 0.3963 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1184 - val_dense_3_loss: 0.2173 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9080
Epoch 84/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3934 - dense_1_loss: 0.0599 - dense_2_loss: 0.1163 - dense_3_loss: 0.2171 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9654 - dense_3_accuracy: 0.9080 - val_loss: 0.3960 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1184 - val_dense_3_loss: 0.2172 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9081
Epoch 85/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.3933 - dense_1_loss: 0.0599 - dense_2_loss: 0.1163 - dense_3_loss: 0.2171 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9654 - dense_3_accuracy: 0.9080 - val_loss: 0.3965 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1185 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9079
Epoch 86/100000
921/921 [==============================] - 24s 27ms/step - loss: 0.3932 - dense_1_loss: 0.0599 - dense_2_loss: 0.1162 - dense_3_loss: 0.2171 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9654 - dense_3_accuracy: 0.9080 - val_loss: 0.3966 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1185 - val_dense_3_loss: 0.2176 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9078
Epoch 87/100000
921/921 [==============================] - 26s 28ms/step - loss: 0.3931 - dense_1_loss: 0.0599 - dense_2_loss: 0.1162 - dense_3_loss: 0.2171 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9654 - dense_3_accuracy: 0.9080 - val_loss: 0.3957 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1181 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9081
Epoch 88/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.3929 - dense_1_loss: 0.0598 - dense_2_loss: 0.1161 - dense_3_loss: 0.2170 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9654 - dense_3_accuracy: 0.9080 - val_loss: 0.3958 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1182 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9081
Epoch 89/100000
921/921 [==============================] - 22s 24ms/step - loss: 0.3929 - dense_1_loss: 0.0598 - dense_2_loss: 0.1161 - dense_3_loss: 0.2171 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9654 - dense_3_accuracy: 0.9079 - val_loss: 0.3961 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1182 - val_dense_3_loss: 0.2174 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9080
Epoch 90/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3931 - dense_1_loss: 0.0599 - dense_2_loss: 0.1161 - dense_3_loss: 0.2171 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9655 - dense_3_accuracy: 0.9080 - val_loss: 0.3964 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1185 - val_dense_3_loss: 0.2173 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9081
Epoch 91/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3928 - dense_1_loss: 0.0598 - dense_2_loss: 0.1160 - dense_3_loss: 0.2170 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9655 - dense_3_accuracy: 0.9080 - val_loss: 0.3956 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1181 - val_dense_3_loss: 0.2170 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9081
Epoch 92/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3927 - dense_1_loss: 0.0597 - dense_2_loss: 0.1159 - dense_3_loss: 0.2170 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9655 - dense_3_accuracy: 0.9080 - val_loss: 0.3958 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1181 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9081
Epoch 93/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3928 - dense_1_loss: 0.0598 - dense_2_loss: 0.1160 - dense_3_loss: 0.2170 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9655 - dense_3_accuracy: 0.9080 - val_loss: 0.3960 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1183 - val_dense_3_loss: 0.2172 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9081
Epoch 94/100000
921/921 [==============================] - 21s 23ms/step - loss: 0.3934 - dense_1_loss: 0.0599 - dense_2_loss: 0.1163 - dense_3_loss: 0.2171 - dense_1_accuracy: 0.9802 - dense_2_accuracy: 0.9654 - dense_3_accuracy: 0.9080 - val_loss: 0.3954 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2170 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9081
Epoch 95/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3924 - dense_1_loss: 0.0597 - dense_2_loss: 0.1158 - dense_3_loss: 0.2170 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9655 - dense_3_accuracy: 0.9080 - val_loss: 0.3958 - val_dense_1_loss: 0.0606 - val_dense_2_loss: 0.1182 - val_dense_3_loss: 0.2170 - val_dense_1_accuracy: 0.9802 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9081
Epoch 96/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3923 - dense_1_loss: 0.0597 - dense_2_loss: 0.1157 - dense_3_loss: 0.2169 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9655 - dense_3_accuracy: 0.9081 - val_loss: 0.3955 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2170 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9080
Epoch 97/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3923 - dense_1_loss: 0.0597 - dense_2_loss: 0.1157 - dense_3_loss: 0.2169 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9655 - dense_3_accuracy: 0.9080 - val_loss: 0.3957 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1182 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9652 - val_dense_3_accuracy: 0.9081
Epoch 98/100000
921/921 [==============================] - 25s 27ms/step - loss: 0.3923 - dense_1_loss: 0.0597 - dense_2_loss: 0.1157 - dense_3_loss: 0.2170 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9655 - dense_3_accuracy: 0.9080 - val_loss: 0.3955 - val_dense_1_loss: 0.0603 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2172 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9080
Epoch 99/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3922 - dense_1_loss: 0.0596 - dense_2_loss: 0.1156 - dense_3_loss: 0.2169 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9656 - dense_3_accuracy: 0.9080 - val_loss: 0.3953 - val_dense_1_loss: 0.0603 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2170 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9082
Epoch 100/100000
921/921 [==============================] - 22s 24ms/step - loss: 0.3923 - dense_1_loss: 0.0596 - dense_2_loss: 0.1156 - dense_3_loss: 0.2170 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9656 - dense_3_accuracy: 0.9080 - val_loss: 0.3954 - val_dense_1_loss: 0.0603 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9804 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9080
Epoch 101/100000
921/921 [==============================] - 26s 28ms/step - loss: 0.3922 - dense_1_loss: 0.0596 - dense_2_loss: 0.1156 - dense_3_loss: 0.2170 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9656 - dense_3_accuracy: 0.9080 - val_loss: 0.3956 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1181 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9081
Epoch 102/100000
921/921 [==============================] - 25s 27ms/step - loss: 0.3920 - dense_1_loss: 0.0596 - dense_2_loss: 0.1155 - dense_3_loss: 0.2169 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9656 - dense_3_accuracy: 0.9081 - val_loss: 0.3955 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9081
Epoch 103/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3919 - dense_1_loss: 0.0596 - dense_2_loss: 0.1155 - dense_3_loss: 0.2169 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9656 - dense_3_accuracy: 0.9080 - val_loss: 0.3957 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1182 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9081
Epoch 104/100000
921/921 [==============================] - 25s 27ms/step - loss: 0.3919 - dense_1_loss: 0.0596 - dense_2_loss: 0.1154 - dense_3_loss: 0.2169 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9656 - dense_3_accuracy: 0.9080 - val_loss: 0.3954 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2170 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9081
Epoch 105/100000
921/921 [==============================] - 24s 27ms/step - loss: 0.3918 - dense_1_loss: 0.0595 - dense_2_loss: 0.1154 - dense_3_loss: 0.2169 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9656 - dense_3_accuracy: 0.9080 - val_loss: 0.3957 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1181 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9081
Epoch 106/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3918 - dense_1_loss: 0.0595 - dense_2_loss: 0.1154 - dense_3_loss: 0.2169 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9656 - dense_3_accuracy: 0.9081 - val_loss: 0.3953 - val_dense_1_loss: 0.0603 - val_dense_2_loss: 0.1179 - val_dense_3_loss: 0.2170 - val_dense_1_accuracy: 0.9804 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9081
Epoch 107/100000
921/921 [==============================] - 27s 29ms/step - loss: 0.3917 - dense_1_loss: 0.0595 - dense_2_loss: 0.1154 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9656 - dense_3_accuracy: 0.9080 - val_loss: 0.3954 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1178 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9080
Epoch 108/100000
921/921 [==============================] - 25s 27ms/step - loss: 0.3916 - dense_1_loss: 0.0595 - dense_2_loss: 0.1153 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9804 - dense_2_accuracy: 0.9657 - dense_3_accuracy: 0.9080 - val_loss: 0.3955 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9081
Epoch 109/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3916 - dense_1_loss: 0.0595 - dense_2_loss: 0.1153 - dense_3_loss: 0.2169 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9656 - dense_3_accuracy: 0.9080 - val_loss: 0.3951 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1178 - val_dense_3_loss: 0.2169 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9082
Epoch 110/100000
921/921 [==============================] - 25s 27ms/step - loss: 0.3914 - dense_1_loss: 0.0594 - dense_2_loss: 0.1152 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9804 - dense_2_accuracy: 0.9657 - dense_3_accuracy: 0.9081 - val_loss: 0.3957 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1181 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9653 - val_dense_3_accuracy: 0.9080
Epoch 111/100000
921/921 [==============================] - 27s 29ms/step - loss: 0.3915 - dense_1_loss: 0.0594 - dense_2_loss: 0.1152 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9803 - dense_2_accuracy: 0.9656 - dense_3_accuracy: 0.9080 - val_loss: 0.3958 - val_dense_1_loss: 0.0605 - val_dense_2_loss: 0.1181 - val_dense_3_loss: 0.2172 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9080
Epoch 112/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3914 - dense_1_loss: 0.0595 - dense_2_loss: 0.1152 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9804 - dense_2_accuracy: 0.9657 - dense_3_accuracy: 0.9080 - val_loss: 0.3953 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2170 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9080
Epoch 113/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3913 - dense_1_loss: 0.0594 - dense_2_loss: 0.1151 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9804 - dense_2_accuracy: 0.9657 - dense_3_accuracy: 0.9081 - val_loss: 0.3954 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2171 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9081
Epoch 114/100000
921/921 [==============================] - 24s 26ms/step - loss: 0.3914 - dense_1_loss: 0.0594 - dense_2_loss: 0.1151 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9804 - dense_2_accuracy: 0.9657 - dense_3_accuracy: 0.9080 - val_loss: 0.3952 - val_dense_1_loss: 0.0603 - val_dense_2_loss: 0.1179 - val_dense_3_loss: 0.2170 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9081
Epoch 115/100000
921/921 [==============================] - 22s 24ms/step - loss: 0.3912 - dense_1_loss: 0.0594 - dense_2_loss: 0.1150 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9804 - dense_2_accuracy: 0.9657 - dense_3_accuracy: 0.9081 - val_loss: 0.3953 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1178 - val_dense_3_loss: 0.2170 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9080
Epoch 116/100000
921/921 [==============================] - 27s 29ms/step - loss: 0.3912 - dense_1_loss: 0.0594 - dense_2_loss: 0.1151 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9804 - dense_2_accuracy: 0.9657 - dense_3_accuracy: 0.9081 - val_loss: 0.3951 - val_dense_1_loss: 0.0603 - val_dense_2_loss: 0.1178 - val_dense_3_loss: 0.2170 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9082
Epoch 117/100000
921/921 [==============================] - 25s 27ms/step - loss: 0.3911 - dense_1_loss: 0.0594 - dense_2_loss: 0.1150 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9804 - dense_2_accuracy: 0.9657 - dense_3_accuracy: 0.9081 - val_loss: 0.3954 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2169 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9081
Epoch 118/100000
921/921 [==============================] - 24s 27ms/step - loss: 0.3910 - dense_1_loss: 0.0593 - dense_2_loss: 0.1149 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9804 - dense_2_accuracy: 0.9657 - dense_3_accuracy: 0.9081 - val_loss: 0.3963 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1179 - val_dense_3_loss: 0.2180 - val_dense_1_accuracy: 0.9804 - val_dense_2_accuracy: 0.9655 - val_dense_3_accuracy: 0.9080
Epoch 119/100000
921/921 [==============================] - 23s 25ms/step - loss: 0.3910 - dense_1_loss: 0.0593 - dense_2_loss: 0.1149 - dense_3_loss: 0.2168 - dense_1_accuracy: 0.9804 - dense_2_accuracy: 0.9657 - dense_3_accuracy: 0.9081 - val_loss: 0.3956 - val_dense_1_loss: 0.0604 - val_dense_2_loss: 0.1180 - val_dense_3_loss: 0.2172 - val_dense_1_accuracy: 0.9803 - val_dense_2_accuracy: 0.9654 - val_dense_3_accuracy: 0.9080
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 99)]         0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 99)]         0           []                               
                                                                                                  
 embedding (Embedding)          (None, 99, 8)        328         ['input_1[0][0]']                
                                                                                                  
 embedding_1 (Embedding)        (None, 99, 32)       59520       ['input_2[0][0]']                
                                                                                                  
 input_3 (InputLayer)           [(None, 99, 3)]      0           []                               
                                                                                                  
 concatenate (Concatenate)      (None, 99, 43)       0           ['embedding[0][0]',              
                                                                  'embedding_1[0][0]',            
                                                                  'input_3[0][0]']                
                                                                                                  
 lstm (LSTM)                    (None, 99, 64)       27648       ['concatenate[0][0]']            
                                                                                                  
 dense (Dense)                  (None, 99, 128)      8320        ['lstm[0][0]']                   
                                                                                                  
 batch_normalization (BatchNorm  (None, 99, 128)     512         ['dense[0][0]']                  
 alization)                                                                                       
                                                                                                  
 activation (Activation)        (None, 99, 128)      0           ['batch_normalization[0][0]']    
                                                                                                  
==================================================================================================
Total params: 96,328
Trainable params: 0
Non-trainable params: 96,328
__________________________________________________________________________________________________
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 99)]         0           []                               
                                                                                                  
 input_2 (InputLayer)           [(None, 99)]         0           []                               
                                                                                                  
 input_3 (InputLayer)           [(None, 99, 3)]      0           []                               
                                                                                                  
 input_4 (InputLayer)           [(None, 1)]          0           []                               
                                                                                                  
 model_1 (Functional)           (None, 99, 128)      96328       ['input_1[0][0]',                
                                                                  'input_2[0][0]',                
                                                                  'input_3[0][0]']                
                                                                                                  
 embedding_1 (Embedding)        multiple             59520       ['input_4[0][0]']                
                                                                                                  
 dense_4 (Dense)                (None, 99, 2)        258         ['model_1[0][0]']                
                                                                                                  
 flatten (Flatten)              (None, 32)           0           ['embedding_1[1][0]']            
                                                                                                  
 flatten_1 (Flatten)            (None, 198)          0           ['dense_4[0][0]']                
                                                                                                  
 concatenate_1 (Concatenate)    (None, 230)          0           ['flatten[0][0]',                
                                                                  'flatten_1[0][0]']              
                                                                                                  
 dense_5 (Dense)                (None, 32)           7392        ['concatenate_1[0][0]']          
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 32)          128         ['dense_5[0][0]']                
 rmalization)                                                                                     
                                                                                                  
 activation_1 (Activation)      (None, 32)           0           ['batch_normalization_1[0][0]']  
                                                                                                  
 dense_6 (Dense)                (None, 32)           1056        ['activation_1[0][0]']           
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 32)          128         ['dense_6[0][0]']                
 rmalization)                                                                                     
                                                                                                  
 activation_2 (Activation)      (None, 32)           0           ['batch_normalization_2[0][0]']  
                                                                                                  
 dense_7 (Dense)                (None, 1)            33          ['activation_2[0][0]']           
                                                                                                  
==================================================================================================
Total params: 105,323
Trainable params: 8,867
Non-trainable params: 96,456
__________________________________________________________________________________________________
**train**
The number of data is 58649
First data is ('00084390-2772-11ed-a198-4b0f4fece200', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
**valid**
The number of data is 19634
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [410, 410, 411, 411, 412, 413, 414, 415, 416, 417, 418, 418, 419, 419, 420, 421, 422, 423, 424, 425, 402, 402, 403, 403, 404, 405, 406, 407, 408, 409, 499, 508, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511, 511, 512, 513, 514, 515, 516, 517, 518, 527, 519, 519, 520, 521, 522, 523, 524, 525, 526, 594, 595, 596, 596, 597, 598, 599, 600, 601, 602, 603, 604, 603, 612, 604, 605, 606, 607, 608, 609, 610, 611, 613, 613, 614, 614, 615, 616, 617, 618, 619, 620, 621, 621, 622, 622, 623, 624, 625, 626, 627, 628, 683, 684, 685, 685, 686, 687, 688, 689, 690, 691, 692, 692, 693, 693, 694, 695, 696, 697, 698, 699, 700, 700, 701, 701, 702, 703, 704, 705, 706, 707, 772, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])
**test**
The number of data is 19395
First data is ('0012a750-6c87-11ec-8ddc-a7b35ace4410', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 60, 61, 62, 63, 64, 64, 65, 65, 66, 67, 68, 69, 70, 71, 71, 72, 72, 73, 74, 75, 76, 77, 78, 79, 79, 80, 80, 81, 82, 83, 131, 132, 133, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 142, 143, 144, 145, 146, 147, 148, 208, 208, 209, 209, 210, 211, 212, 213, 214, 215, 226, 235, 227, 228, 229, 230, 231, 232, 233, 234, 236, 245, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 247, 248, 249, 250, 251, 252, 253, 254, 255, 264, 256, 257, 258, 259, 260, 261, 262, 263, 315, 324, 316, 317, 318, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 343, 335, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 346, 347, 348, 349, 350, 351, 352, 353, 362, 354, 355, 356, 357, 358, 359, 360, 361, 402, 402, 403, 403, 404, 405, 406, 407, 408, 409, 418, 418, 419, 419, 420, 421, 422, 423, 424, 425], [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])
Before Remapping, max value of problemid is 2378
After Remapping, max value of problemid is 1865
** After Remapping ProblemID **
**train**
The number of data is 58649
First data is ('00084390-2772-11ed-a198-4b0f4fece200', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
**valid**
The number of data is 19634
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [320, 320, 321, 321, 322, 323, 324, 325, 326, 327, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 398, 407, 399, 400, 401, 402, 403, 404, 405, 406, 408, 409, 410, 410, 411, 412, 413, 414, 415, 416, 417, 426, 418, 418, 419, 420, 421, 422, 423, 424, 425, 473, 474, 475, 475, 476, 477, 478, 479, 480, 481, 482, 483, 482, 491, 483, 484, 485, 486, 487, 488, 489, 490, 492, 492, 493, 493, 494, 495, 496, 497, 498, 499, 500, 500, 501, 501, 502, 503, 504, 505, 506, 507, 543, 544, 545, 545, 546, 547, 548, 549, 550, 551, 552, 552, 553, 553, 554, 555, 556, 557, 558, 559, 560, 560, 561, 561, 562, 563, 564, 565, 566, 567, 619, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])
**test**
The number of data is 19395
First data is ('0012a750-6c87-11ec-8ddc-a7b35ace4410', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 51, 52, 53, 54, 55, 55, 56, 56, 57, 58, 59, 60, 61, 62, 62, 63, 63, 64, 65, 66, 67, 68, 69, 70, 70, 71, 71, 72, 73, 74, 105, 106, 107, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 116, 117, 118, 119, 120, 121, 122, 160, 160, 161, 161, 162, 163, 164, 165, 166, 167, 178, 187, 179, 180, 181, 182, 183, 184, 185, 186, 188, 197, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 199, 200, 201, 202, 203, 204, 205, 206, 207, 216, 208, 209, 210, 211, 212, 213, 214, 215, 245, 254, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 273, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 276, 277, 278, 279, 280, 281, 282, 283, 292, 284, 285, 286, 287, 288, 289, 290, 291, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335], [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])
Before splitted train length 58649, After splitted train length 6324410
Before splitted valid length 19634, After splitted valid length 2128685
Before splitted test length 19395, After splitted test length 2124217
**train**
The number of data is 58649
First data is ('00084390-2772-11ed-a198-4b0f4fece200', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
**valid**
The number of data is 19634
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [410, 410, 411, 411, 412, 413, 414, 415, 416, 417, 418, 418, 419, 419, 420, 421, 422, 423, 424, 425, 402, 402, 403, 403, 404, 405, 406, 407, 408, 409, 499, 508, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511, 511, 512, 513, 514, 515, 516, 517, 518, 527, 519, 519, 520, 521, 522, 523, 524, 525, 526, 594, 595, 596, 596, 597, 598, 599, 600, 601, 602, 603, 604, 603, 612, 604, 605, 606, 607, 608, 609, 610, 611, 613, 613, 614, 614, 615, 616, 617, 618, 619, 620, 621, 621, 622, 622, 623, 624, 625, 626, 627, 628, 683, 684, 685, 685, 686, 687, 688, 689, 690, 691, 692, 692, 693, 693, 694, 695, 696, 697, 698, 699, 700, 700, 701, 701, 702, 703, 704, 705, 706, 707, 772, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])
**test**
The number of data is 19395
First data is ('0012a750-6c87-11ec-8ddc-a7b35ace4410', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 60, 61, 62, 63, 64, 64, 65, 65, 66, 67, 68, 69, 70, 71, 71, 72, 72, 73, 74, 75, 76, 77, 78, 79, 79, 80, 80, 81, 82, 83, 131, 132, 133, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 142, 143, 144, 145, 146, 147, 148, 208, 208, 209, 209, 210, 211, 212, 213, 214, 215, 226, 235, 227, 228, 229, 230, 231, 232, 233, 234, 236, 245, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 247, 248, 249, 250, 251, 252, 253, 254, 255, 264, 256, 257, 258, 259, 260, 261, 262, 263, 315, 324, 316, 317, 318, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 343, 335, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 346, 347, 348, 349, 350, 351, 352, 353, 362, 354, 355, 356, 357, 358, 359, 360, 361, 402, 402, 403, 403, 404, 405, 406, 407, 408, 409, 418, 418, 419, 419, 420, 421, 422, 423, 424, 425], [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])
Before Remapping, max value of problemid is 2378
After Remapping, max value of problemid is 1865
** After Remapping ProblemID **
**train**
The number of data is 58649
First data is ('00084390-2772-11ed-a198-4b0f4fece200', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
**valid**
The number of data is 19634
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [320, 320, 321, 321, 322, 323, 324, 325, 326, 327, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 398, 407, 399, 400, 401, 402, 403, 404, 405, 406, 408, 409, 410, 410, 411, 412, 413, 414, 415, 416, 417, 426, 418, 418, 419, 420, 421, 422, 423, 424, 425, 473, 474, 475, 475, 476, 477, 478, 479, 480, 481, 482, 483, 482, 491, 483, 484, 485, 486, 487, 488, 489, 490, 492, 492, 493, 493, 494, 495, 496, 497, 498, 499, 500, 500, 501, 501, 502, 503, 504, 505, 506, 507, 543, 544, 545, 545, 546, 547, 548, 549, 550, 551, 552, 552, 553, 553, 554, 555, 556, 557, 558, 559, 560, 560, 561, 561, 562, 563, 564, 565, 566, 567, 619, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])
**test**
The number of data is 19395
First data is ('0012a750-6c87-11ec-8ddc-a7b35ace4410', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 51, 52, 53, 54, 55, 55, 56, 56, 57, 58, 59, 60, 61, 62, 62, 63, 63, 64, 65, 66, 67, 68, 69, 70, 70, 71, 71, 72, 73, 74, 105, 106, 107, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 116, 117, 118, 119, 120, 121, 122, 160, 160, 161, 161, 162, 163, 164, 165, 166, 167, 178, 187, 179, 180, 181, 182, 183, 184, 185, 186, 188, 197, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 199, 200, 201, 202, 203, 204, 205, 206, 207, 216, 208, 209, 210, 211, 212, 213, 214, 215, 245, 254, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 273, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 276, 277, 278, 279, 280, 281, 282, 283, 292, 284, 285, 286, 287, 288, 289, 290, 291, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335], [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])
Before splitted train length 58649, After splitted train length 6324410
Before splitted valid length 19634, After splitted valid length 2128685
Before splitted test length 19395, After splitted test length 2124217
**train**
The number of data is 58649
First data is ('00084390-2772-11ed-a198-4b0f4fece200', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
**valid**
The number of data is 19634
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [410, 410, 411, 411, 412, 413, 414, 415, 416, 417, 418, 418, 419, 419, 420, 421, 422, 423, 424, 425, 402, 402, 403, 403, 404, 405, 406, 407, 408, 409, 499, 508, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511, 511, 512, 513, 514, 515, 516, 517, 518, 527, 519, 519, 520, 521, 522, 523, 524, 525, 526, 594, 595, 596, 596, 597, 598, 599, 600, 601, 602, 603, 604, 603, 612, 604, 605, 606, 607, 608, 609, 610, 611, 613, 613, 614, 614, 615, 616, 617, 618, 619, 620, 621, 621, 622, 622, 623, 624, 625, 626, 627, 628, 683, 684, 685, 685, 686, 687, 688, 689, 690, 691, 692, 692, 693, 693, 694, 695, 696, 697, 698, 699, 700, 700, 701, 701, 702, 703, 704, 705, 706, 707, 772, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])
**test**
The number of data is 19395
First data is ('0012a750-6c87-11ec-8ddc-a7b35ace4410', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 60, 61, 62, 63, 64, 64, 65, 65, 66, 67, 68, 69, 70, 71, 71, 72, 72, 73, 74, 75, 76, 77, 78, 79, 79, 80, 80, 81, 82, 83, 131, 132, 133, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 142, 143, 144, 145, 146, 147, 148, 208, 208, 209, 209, 210, 211, 212, 213, 214, 215, 226, 235, 227, 228, 229, 230, 231, 232, 233, 234, 236, 245, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 247, 248, 249, 250, 251, 252, 253, 254, 255, 264, 256, 257, 258, 259, 260, 261, 262, 263, 315, 324, 316, 317, 318, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 343, 335, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 346, 347, 348, 349, 350, 351, 352, 353, 362, 354, 355, 356, 357, 358, 359, 360, 361, 402, 402, 403, 403, 404, 405, 406, 407, 408, 409, 418, 418, 419, 419, 420, 421, 422, 423, 424, 425], [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])
Before Remapping, max value of problemid is 2378
After Remapping, max value of problemid is 1865
** After Remapping ProblemID **
**train**
The number of data is 58649
First data is ('00084390-2772-11ed-a198-4b0f4fece200', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
**valid**
The number of data is 19634
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [320, 320, 321, 321, 322, 323, 324, 325, 326, 327, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 398, 407, 399, 400, 401, 402, 403, 404, 405, 406, 408, 409, 410, 410, 411, 412, 413, 414, 415, 416, 417, 426, 418, 418, 419, 420, 421, 422, 423, 424, 425, 473, 474, 475, 475, 476, 477, 478, 479, 480, 481, 482, 483, 482, 491, 483, 484, 485, 486, 487, 488, 489, 490, 492, 492, 493, 493, 494, 495, 496, 497, 498, 499, 500, 500, 501, 501, 502, 503, 504, 505, 506, 507, 543, 544, 545, 545, 546, 547, 548, 549, 550, 551, 552, 552, 553, 553, 554, 555, 556, 557, 558, 559, 560, 560, 561, 561, 562, 563, 564, 565, 566, 567, 619, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])
**test**
The number of data is 19395
First data is ('0012a750-6c87-11ec-8ddc-a7b35ace4410', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 51, 52, 53, 54, 55, 55, 56, 56, 57, 58, 59, 60, 61, 62, 62, 63, 63, 64, 65, 66, 67, 68, 69, 70, 70, 71, 71, 72, 73, 74, 105, 106, 107, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 116, 117, 118, 119, 120, 121, 122, 160, 160, 161, 161, 162, 163, 164, 165, 166, 167, 178, 187, 179, 180, 181, 182, 183, 184, 185, 186, 188, 197, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 199, 200, 201, 202, 203, 204, 205, 206, 207, 216, 208, 209, 210, 211, 212, 213, 214, 215, 245, 254, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 273, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 276, 277, 278, 279, 280, 281, 282, 283, 292, 284, 285, 286, 287, 288, 289, 290, 291, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335], [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])
Before splitted train length 58649, After splitted train length 6324410
Before splitted valid length 19634, After splitted valid length 2128685
Before splitted test length 19395, After splitted test length 2124217
**train**
The number of data is 58649
First data is ('00084390-2772-11ed-a198-4b0f4fece200', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
**valid**
The number of data is 19634
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [410, 410, 411, 411, 412, 413, 414, 415, 416, 417, 418, 418, 419, 419, 420, 421, 422, 423, 424, 425, 402, 402, 403, 403, 404, 405, 406, 407, 408, 409, 499, 508, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511, 511, 512, 513, 514, 515, 516, 517, 518, 527, 519, 519, 520, 521, 522, 523, 524, 525, 526, 594, 595, 596, 596, 597, 598, 599, 600, 601, 602, 603, 604, 603, 612, 604, 605, 606, 607, 608, 609, 610, 611, 613, 613, 614, 614, 615, 616, 617, 618, 619, 620, 621, 621, 622, 622, 623, 624, 625, 626, 627, 628, 683, 684, 685, 685, 686, 687, 688, 689, 690, 691, 692, 692, 693, 693, 694, 695, 696, 697, 698, 699, 700, 700, 701, 701, 702, 703, 704, 705, 706, 707, 772, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])
**test**
The number of data is 19395
First data is ('0012a750-6c87-11ec-8ddc-a7b35ace4410', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 60, 61, 62, 63, 64, 64, 65, 65, 66, 67, 68, 69, 70, 71, 71, 72, 72, 73, 74, 75, 76, 77, 78, 79, 79, 80, 80, 81, 82, 83, 131, 132, 133, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 142, 143, 144, 145, 146, 147, 148, 208, 208, 209, 209, 210, 211, 212, 213, 214, 215, 226, 235, 227, 228, 229, 230, 231, 232, 233, 234, 236, 245, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 247, 248, 249, 250, 251, 252, 253, 254, 255, 264, 256, 257, 258, 259, 260, 261, 262, 263, 315, 324, 316, 317, 318, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 343, 335, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 346, 347, 348, 349, 350, 351, 352, 353, 362, 354, 355, 356, 357, 358, 359, 360, 361, 402, 402, 403, 403, 404, 405, 406, 407, 408, 409, 418, 418, 419, 419, 420, 421, 422, 423, 424, 425], [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])
Before Remapping, max value of problemid is 2378
After Remapping, max value of problemid is 1865
** After Remapping ProblemID **
**train**
The number of data is 58649
First data is ('00084390-2772-11ed-a198-4b0f4fece200', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
**valid**
The number of data is 19634
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [320, 320, 321, 321, 322, 323, 324, 325, 326, 327, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 398, 407, 399, 400, 401, 402, 403, 404, 405, 406, 408, 409, 410, 410, 411, 412, 413, 414, 415, 416, 417, 426, 418, 418, 419, 420, 421, 422, 423, 424, 425, 473, 474, 475, 475, 476, 477, 478, 479, 480, 481, 482, 483, 482, 491, 483, 484, 485, 486, 487, 488, 489, 490, 492, 492, 493, 493, 494, 495, 496, 497, 498, 499, 500, 500, 501, 501, 502, 503, 504, 505, 506, 507, 543, 544, 545, 545, 546, 547, 548, 549, 550, 551, 552, 552, 553, 553, 554, 555, 556, 557, 558, 559, 560, 560, 561, 561, 562, 563, 564, 565, 566, 567, 619, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])
**test**
The number of data is 19395
First data is ('0012a750-6c87-11ec-8ddc-a7b35ace4410', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 51, 52, 53, 54, 55, 55, 56, 56, 57, 58, 59, 60, 61, 62, 62, 63, 63, 64, 65, 66, 67, 68, 69, 70, 70, 71, 71, 72, 73, 74, 105, 106, 107, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 116, 117, 118, 119, 120, 121, 122, 160, 160, 161, 161, 162, 163, 164, 165, 166, 167, 178, 187, 179, 180, 181, 182, 183, 184, 185, 186, 188, 197, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 199, 200, 201, 202, 203, 204, 205, 206, 207, 216, 208, 209, 210, 211, 212, 213, 214, 215, 245, 254, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 273, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 276, 277, 278, 279, 280, 281, 282, 283, 292, 284, 285, 286, 287, 288, 289, 290, 291, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335], [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])
**train**
The number of data is 58649
First data is ('00084390-2772-11ed-a198-4b0f4fece200', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
**valid**
The number of data is 19634
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [410, 410, 411, 411, 412, 413, 414, 415, 416, 417, 418, 418, 419, 419, 420, 421, 422, 423, 424, 425, 402, 402, 403, 403, 404, 405, 406, 407, 408, 409, 499, 508, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510, 511, 511, 512, 513, 514, 515, 516, 517, 518, 527, 519, 519, 520, 521, 522, 523, 524, 525, 526, 594, 595, 596, 596, 597, 598, 599, 600, 601, 602, 603, 604, 603, 612, 604, 605, 606, 607, 608, 609, 610, 611, 613, 613, 614, 614, 615, 616, 617, 618, 619, 620, 621, 621, 622, 622, 623, 624, 625, 626, 627, 628, 683, 684, 685, 685, 686, 687, 688, 689, 690, 691, 692, 692, 693, 693, 694, 695, 696, 697, 698, 699, 700, 700, 701, 701, 702, 703, 704, 705, 706, 707, 772, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797, 790, 790, 791, 791, 792, 793, 794, 795, 796, 797], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])
**test**
The number of data is 19395
First data is ('0012a750-6c87-11ec-8ddc-a7b35ace4410', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 60, 61, 62, 63, 64, 64, 65, 65, 66, 67, 68, 69, 70, 71, 71, 72, 72, 73, 74, 75, 76, 77, 78, 79, 79, 80, 80, 81, 82, 83, 131, 132, 133, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 142, 143, 144, 145, 146, 147, 148, 208, 208, 209, 209, 210, 211, 212, 213, 214, 215, 226, 235, 227, 228, 229, 230, 231, 232, 233, 234, 236, 245, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 247, 248, 249, 250, 251, 252, 253, 254, 255, 264, 256, 257, 258, 259, 260, 261, 262, 263, 315, 324, 316, 317, 318, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 343, 335, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 346, 347, 348, 349, 350, 351, 352, 353, 362, 354, 355, 356, 357, 358, 359, 360, 361, 402, 402, 403, 403, 404, 405, 406, 407, 408, 409, 418, 418, 419, 419, 420, 421, 422, 423, 424, 425], [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])
Before Remapping, max value of problemid is 2378
After Remapping, max value of problemid is 1865
** After Remapping ProblemID **
**train**
The number of data is 58649
First data is ('00084390-2772-11ed-a198-4b0f4fece200', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
**valid**
The number of data is 19634
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [320, 320, 321, 321, 322, 323, 324, 325, 326, 327, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 398, 407, 399, 400, 401, 402, 403, 404, 405, 406, 408, 409, 410, 410, 411, 412, 413, 414, 415, 416, 417, 426, 418, 418, 419, 420, 421, 422, 423, 424, 425, 473, 474, 475, 475, 476, 477, 478, 479, 480, 481, 482, 483, 482, 491, 483, 484, 485, 486, 487, 488, 489, 490, 492, 492, 493, 493, 494, 495, 496, 497, 498, 499, 500, 500, 501, 501, 502, 503, 504, 505, 506, 507, 543, 544, 545, 545, 546, 547, 548, 549, 550, 551, 552, 552, 553, 553, 554, 555, 556, 557, 558, 559, 560, 560, 561, 561, 562, 563, 564, 565, 566, 567, 619, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])
**test**
The number of data is 19395
First data is ('0012a750-6c87-11ec-8ddc-a7b35ace4410', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 51, 52, 53, 54, 55, 55, 56, 56, 57, 58, 59, 60, 61, 62, 62, 63, 63, 64, 65, 66, 67, 68, 69, 70, 70, 71, 71, 72, 73, 74, 105, 106, 107, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 116, 117, 118, 119, 120, 121, 122, 160, 160, 161, 161, 162, 163, 164, 165, 166, 167, 178, 187, 179, 180, 181, 182, 183, 184, 185, 186, 188, 197, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 199, 200, 201, 202, 203, 204, 205, 206, 207, 216, 208, 209, 210, 211, 212, 213, 214, 215, 245, 254, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 273, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 276, 277, 278, 279, 280, 281, 282, 283, 292, 284, 285, 286, 287, 288, 289, 290, 291, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335], [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])
Before splitted train length 58649, After splitted train length 6324410
Before splitted valid length 19634, After splitted valid length 2128685
Before splitted test length 19395, After splitted test length 2124217
Training... starting
Epoch 1/10000
2023-08-14 06:25:41.276985: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100
12352/12352 [==============================] - 713s 57ms/step - loss: 0.3901 - accuracy: 0.8360 - val_loss: 0.3889 - val_accuracy: 0.8428
Epoch 2/10000
12352/12352 [==============================] - 707s 57ms/step - loss: 0.3823 - accuracy: 0.8373 - val_loss: 0.3815 - val_accuracy: 0.8406
Epoch 3/10000
12352/12352 [==============================] - 707s 57ms/step - loss: 0.3812 - accuracy: 0.8373 - val_loss: 0.3804 - val_accuracy: 0.8398
Epoch 4/10000
12352/12352 [==============================] - 707s 57ms/step - loss: 0.3806 - accuracy: 0.8374 - val_loss: 0.3797 - val_accuracy: 0.8393
Epoch 5/10000
12352/12352 [==============================] - 707s 57ms/step - loss: 0.3802 - accuracy: 0.8375 - val_loss: 0.3793 - val_accuracy: 0.8391
Epoch 6/10000
12352/12352 [==============================] - 708s 57ms/step - loss: 0.3799 - accuracy: 0.8375 - val_loss: 0.3789 - val_accuracy: 0.8394
Epoch 7/10000
12352/12352 [==============================] - 709s 57ms/step - loss: 0.3797 - accuracy: 0.8376 - val_loss: 0.3787 - val_accuracy: 0.8402
Epoch 8/10000
12352/12352 [==============================] - 707s 57ms/step - loss: 0.3795 - accuracy: 0.8376 - val_loss: 0.3789 - val_accuracy: 0.8409
Epoch 9/10000
12352/12352 [==============================] - 708s 57ms/step - loss: 0.3794 - accuracy: 0.8375 - val_loss: 0.3795 - val_accuracy: 0.8409
Epoch 10/10000
12352/12352 [==============================] - 707s 57ms/step - loss: 0.3792 - accuracy: 0.8376 - val_loss: 0.3803 - val_accuracy: 0.8407
Epoch 11/10000
12352/12352 [==============================] - 708s 57ms/step - loss: 0.3791 - accuracy: 0.8376 - val_loss: 0.3812 - val_accuracy: 0.8400
Epoch 12/10000
12352/12352 [==============================] - 706s 57ms/step - loss: 0.3790 - accuracy: 0.8376 - val_loss: 0.3821 - val_accuracy: 0.8391
Epoch 13/10000
12352/12352 [==============================] - 710s 57ms/step - loss: 0.3789 - accuracy: 0.8376 - val_loss: 0.3832 - val_accuracy: 0.8378
Epoch 14/10000
12352/12352 [==============================] - 707s 57ms/step - loss: 0.3789 - accuracy: 0.8376 - val_loss: 0.3841 - val_accuracy: 0.8376
Epoch 15/10000
12352/12352 [==============================] - 709s 57ms/step - loss: 0.3788 - accuracy: 0.8377 - val_loss: 0.3850 - val_accuracy: 0.8372
Epoch 16/10000
12352/12352 [==============================] - 711s 58ms/step - loss: 0.3787 - accuracy: 0.8376 - val_loss: 0.3860 - val_accuracy: 0.8368
Epoch 17/10000
12352/12352 [==============================] - 707s 57ms/step - loss: 0.3787 - accuracy: 0.8376 - val_loss: 0.3865 - val_accuracy: 0.8353
Training... ends


**Second Try for Model3 with Patience 30**
**train**
The number of data is 58649
First data is ('00084390-2772-11ed-a198-4b0f4fece200', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])
**valid**
The number of data is 19634
First data is ('000d1500-7c74-11eb-991b-d3071bf4a710', [7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 10, 9, 10, 10, 10, 8, 3, 8, 8, 3, 10, 10, 10, 10, 8, 3, 8, 10, 3, 9, 10, 9, 10, 10, 10, 10, 3, 8, 3, 3, 8, 10, 10, 10, 10, 8, 3, 3, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 3, 13, 13, 9, 10, 10, 10, 10, 12, 13, 3, 14, 14, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 9, 10, 10, 10, 10, 3, 8, 3, 8, 8, 9, 15, 15, 15, 15, 8, 3, 3, 8, 3, 16, 15, 15, 15, 15, 8, 3, 8, 8, 8, 16, 18, 18, 18, 18, 8, 6, 6, 8, 8, 16, 18, 18, 18, 18, 8, 8, 8, 6, 19, 16, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9, 18, 18, 18, 18, 8, 3, 8, 6, 3, 9], [320, 320, 321, 321, 322, 323, 324, 325, 326, 327, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 398, 407, 399, 400, 401, 402, 403, 404, 405, 406, 408, 409, 410, 410, 411, 412, 413, 414, 415, 416, 417, 426, 418, 418, 419, 420, 421, 422, 423, 424, 425, 473, 474, 475, 475, 476, 477, 478, 479, 480, 481, 482, 483, 482, 491, 483, 484, 485, 486, 487, 488, 489, 490, 492, 492, 493, 493, 494, 495, 496, 497, 498, 499, 500, 500, 501, 501, 502, 503, 504, 505, 506, 507, 543, 544, 545, 545, 546, 547, 548, 549, 550, 551, 552, 552, 553, 553, 554, 555, 556, 557, 558, 559, 560, 560, 561, 561, 562, 563, 564, 565, 566, 567, 619, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644, 637, 637, 638, 638, 639, 640, 641, 642, 643, 644], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])
**test**
The number of data is 19395
First data is ('0012a750-6c87-11ec-8ddc-a7b35ace4410', [1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 5, 3, 3, 3, 3, 3, 4, 4, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 4, 5, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 7, 7, 7, 7, 8, 3, 3, 3, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 51, 52, 53, 54, 55, 55, 56, 56, 57, 58, 59, 60, 61, 62, 62, 63, 63, 64, 65, 66, 67, 68, 69, 70, 70, 71, 71, 72, 73, 74, 105, 106, 107, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 116, 117, 118, 119, 120, 121, 122, 160, 160, 161, 161, 162, 163, 164, 165, 166, 167, 178, 187, 179, 180, 181, 182, 183, 184, 185, 186, 188, 197, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 199, 200, 201, 202, 203, 204, 205, 206, 207, 216, 208, 209, 210, 211, 212, 213, 214, 215, 245, 254, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 273, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 276, 277, 278, 279, 280, 281, 282, 283, 292, 284, 285, 286, 287, 288, 289, 290, 291, 312, 312, 313, 313, 314, 315, 316, 317, 318, 319, 328, 328, 329, 329, 330, 331, 332, 333, 334, 335], [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])
Before splitted train length 58649, After splitted train length 6324410
Before splitted valid length 19634, After splitted valid length 2128685
Before splitted test length 19395, After splitted test length 2124217
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 99)]         0           []

 input_2 (InputLayer)           [(None, 99)]         0           []

 input_3 (InputLayer)           [(None, 99, 3)]      0           []

 input_4 (InputLayer)           [(None, 1)]          0           []

 model_1 (Functional)           (None, 99, 128)      96328       ['input_1[0][0]',
                                                                  'input_2[0][0]',
                                                                  'input_3[0][0]']

 embedding_1 (Embedding)        multiple             59520       ['input_4[0][0]']

 dense_4 (Dense)                (None, 99, 2)        258         ['model_1[0][0]']

 flatten (Flatten)              (None, 32)           0           ['embedding_1[1][0]']

 flatten_1 (Flatten)            (None, 198)          0           ['dense_4[0][0]']

 concatenate_1 (Concatenate)    (None, 230)          0           ['flatten[0][0]',
                                                                  'flatten_1[0][0]']

 dense_5 (Dense)                (None, 32)           7392        ['concatenate_1[0][0]']

 batch_normalization_1 (BatchNo  (None, 32)          128         ['dense_5[0][0]']
 rmalization)

 activation_1 (Activation)      (None, 32)           0           ['batch_normalization_1[0][0]']

 dense_6 (Dense)                (None, 32)           1056        ['activation_1[0][0]']

 batch_normalization_2 (BatchNo  (None, 32)          128         ['dense_6[0][0]']
 rmalization)

 activation_2 (Activation)      (None, 32)           0           ['batch_normalization_2[0][0]']

 dense_7 (Dense)                (None, 1)            33          ['activation_2[0][0]']

==================================================================================================
Total params: 105,323
Trainable params: 8,867
Non-trainable params: 96,456
__________________________________________________________________________________________________
Training... starting
Epoch 1/10000
2023-08-16 23:05:45.226721: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100
12352/12352 [==============================] - 707s 57ms/step - loss: 0.3925 - accuracy: 0.8348 - val_loss: 0.3886 - val_accuracy: 0.8426
Epoch 2/10000
12352/12352 [==============================] - 705s 57ms/step - loss: 0.3829 - accuracy: 0.8373 - val_loss: 0.3892 - val_accuracy: 0.8427
Epoch 3/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3817 - accuracy: 0.8374 - val_loss: 0.3829 - val_accuracy: 0.8364
Epoch 4/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3811 - accuracy: 0.8376 - val_loss: 0.3898 - val_accuracy: 0.8214
Epoch 5/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3806 - accuracy: 0.8377 - val_loss: 0.3918 - val_accuracy: 0.8161
Epoch 6/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3803 - accuracy: 0.8377 - val_loss: 0.3889 - val_accuracy: 0.8183
Epoch 7/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3800 - accuracy: 0.8378 - val_loss: 0.3858 - val_accuracy: 0.8242
Epoch 8/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3798 - accuracy: 0.8378 - val_loss: 0.3828 - val_accuracy: 0.8279
Epoch 9/10000
12352/12352 [==============================] - 705s 57ms/step - loss: 0.3796 - accuracy: 0.8378 - val_loss: 0.3799 - val_accuracy: 0.8356
Epoch 10/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3795 - accuracy: 0.8378 - val_loss: 0.3788 - val_accuracy: 0.8389
Epoch 11/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3793 - accuracy: 0.8378 - val_loss: 0.3797 - val_accuracy: 0.8402
Epoch 12/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3792 - accuracy: 0.8378 - val_loss: 0.3809 - val_accuracy: 0.8412
Epoch 13/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3791 - accuracy: 0.8378 - val_loss: 0.3827 - val_accuracy: 0.8412
Epoch 14/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3790 - accuracy: 0.8378 - val_loss: 0.3848 - val_accuracy: 0.8410
Epoch 15/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3790 - accuracy: 0.8378 - val_loss: 0.3876 - val_accuracy: 0.8406
Epoch 16/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3789 - accuracy: 0.8378 - val_loss: 0.3905 - val_accuracy: 0.8397
Epoch 17/10000
12352/12352 [==============================] - 704s 57ms/step - loss: 0.3788 - accuracy: 0.8378 - val_loss: 0.3921 - val_accuracy: 0.8381
Epoch 18/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3788 - accuracy: 0.8377 - val_loss: 0.3914 - val_accuracy: 0.8376
Epoch 19/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3787 - accuracy: 0.8377 - val_loss: 0.3906 - val_accuracy: 0.8377
Epoch 20/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3787 - accuracy: 0.8377 - val_loss: 0.3893 - val_accuracy: 0.8378
Epoch 21/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3786 - accuracy: 0.8377 - val_loss: 0.3876 - val_accuracy: 0.8382
Epoch 22/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3786 - accuracy: 0.8377 - val_loss: 0.3858 - val_accuracy: 0.8398
Epoch 23/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3785 - accuracy: 0.8377 - val_loss: 0.3837 - val_accuracy: 0.8404
Epoch 24/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3785 - accuracy: 0.8377 - val_loss: 0.3811 - val_accuracy: 0.8403
Epoch 25/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3785 - accuracy: 0.8377 - val_loss: 0.3791 - val_accuracy: 0.8398
Epoch 26/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3784 - accuracy: 0.8377 - val_loss: 0.3782 - val_accuracy: 0.8390
Epoch 27/10000
12352/12352 [==============================] - 704s 57ms/step - loss: 0.3784 - accuracy: 0.8377 - val_loss: 0.3782 - val_accuracy: 0.8372
Epoch 28/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3784 - accuracy: 0.8377 - val_loss: 0.3801 - val_accuracy: 0.8294
Epoch 29/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3784 - accuracy: 0.8377 - val_loss: 0.3855 - val_accuracy: 0.8185
Epoch 30/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3783 - accuracy: 0.8377 - val_loss: 0.3948 - val_accuracy: 0.8021
Epoch 31/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3783 - accuracy: 0.8377 - val_loss: 0.4024 - val_accuracy: 0.7915
Epoch 32/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3783 - accuracy: 0.8377 - val_loss: 0.4125 - val_accuracy: 0.7774
Epoch 33/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3783 - accuracy: 0.8377 - val_loss: 0.4123 - val_accuracy: 0.7769
Epoch 34/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3782 - accuracy: 0.8377 - val_loss: 0.4065 - val_accuracy: 0.7857
Epoch 35/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3782 - accuracy: 0.8377 - val_loss: 0.4027 - val_accuracy: 0.7907
Epoch 36/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3782 - accuracy: 0.8377 - val_loss: 0.3967 - val_accuracy: 0.7986
Epoch 37/10000
12352/12352 [==============================] - 699s 57ms/step - loss: 0.3782 - accuracy: 0.8377 - val_loss: 0.3913 - val_accuracy: 0.8110
Epoch 38/10000
12352/12352 [==============================] - 704s 57ms/step - loss: 0.3782 - accuracy: 0.8377 - val_loss: 0.3844 - val_accuracy: 0.8219
Epoch 39/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3781 - accuracy: 0.8377 - val_loss: 0.3804 - val_accuracy: 0.8320
Epoch 40/10000
12352/12352 [==============================] - 704s 57ms/step - loss: 0.3781 - accuracy: 0.8377 - val_loss: 0.3780 - val_accuracy: 0.8355
Epoch 41/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3781 - accuracy: 0.8377 - val_loss: 0.3775 - val_accuracy: 0.8374
Epoch 42/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3781 - accuracy: 0.8377 - val_loss: 0.3776 - val_accuracy: 0.8384
Epoch 43/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3781 - accuracy: 0.8377 - val_loss: 0.3778 - val_accuracy: 0.8387
Epoch 44/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3781 - accuracy: 0.8377 - val_loss: 0.3782 - val_accuracy: 0.8391
Epoch 45/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3780 - accuracy: 0.8377 - val_loss: 0.3787 - val_accuracy: 0.8396
Epoch 46/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3780 - accuracy: 0.8377 - val_loss: 0.3792 - val_accuracy: 0.8398
Epoch 47/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3780 - accuracy: 0.8377 - val_loss: 0.3803 - val_accuracy: 0.8398
Epoch 48/10000
12352/12352 [==============================] - 704s 57ms/step - loss: 0.3780 - accuracy: 0.8377 - val_loss: 0.3810 - val_accuracy: 0.8399
Epoch 49/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3780 - accuracy: 0.8377 - val_loss: 0.3817 - val_accuracy: 0.8397
Epoch 50/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3780 - accuracy: 0.8377 - val_loss: 0.3825 - val_accuracy: 0.8395
Epoch 51/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3779 - accuracy: 0.8377 - val_loss: 0.3829 - val_accuracy: 0.8396
Epoch 52/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3779 - accuracy: 0.8377 - val_loss: 0.3824 - val_accuracy: 0.8397
Epoch 53/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3779 - accuracy: 0.8377 - val_loss: 0.3823 - val_accuracy: 0.8398
Epoch 54/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3779 - accuracy: 0.8377 - val_loss: 0.3819 - val_accuracy: 0.8399
Epoch 55/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3779 - accuracy: 0.8377 - val_loss: 0.3815 - val_accuracy: 0.8399
Epoch 56/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3779 - accuracy: 0.8377 - val_loss: 0.3810 - val_accuracy: 0.8399
Epoch 57/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3779 - accuracy: 0.8377 - val_loss: 0.3808 - val_accuracy: 0.8400
Epoch 58/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3779 - accuracy: 0.8377 - val_loss: 0.3806 - val_accuracy: 0.8400
Epoch 59/10000
12352/12352 [==============================] - 699s 57ms/step - loss: 0.3778 - accuracy: 0.8377 - val_loss: 0.3800 - val_accuracy: 0.8399
Epoch 60/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3778 - accuracy: 0.8377 - val_loss: 0.3794 - val_accuracy: 0.8398
Epoch 61/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3778 - accuracy: 0.8377 - val_loss: 0.3789 - val_accuracy: 0.8400
Epoch 62/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3778 - accuracy: 0.8377 - val_loss: 0.3789 - val_accuracy: 0.8401
Epoch 63/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3778 - accuracy: 0.8377 - val_loss: 0.3790 - val_accuracy: 0.8402
Epoch 64/10000
12352/12352 [==============================] - 699s 57ms/step - loss: 0.3778 - accuracy: 0.8378 - val_loss: 0.3788 - val_accuracy: 0.8401
Epoch 65/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3778 - accuracy: 0.8378 - val_loss: 0.3784 - val_accuracy: 0.8400
Epoch 66/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3778 - accuracy: 0.8378 - val_loss: 0.3779 - val_accuracy: 0.8396
Epoch 67/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3778 - accuracy: 0.8378 - val_loss: 0.3774 - val_accuracy: 0.8375
Epoch 68/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3777 - accuracy: 0.8378 - val_loss: 0.3779 - val_accuracy: 0.8357
Epoch 69/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3777 - accuracy: 0.8378 - val_loss: 0.3788 - val_accuracy: 0.8344
Epoch 70/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3777 - accuracy: 0.8378 - val_loss: 0.3815 - val_accuracy: 0.8307
Epoch 71/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3777 - accuracy: 0.8378 - val_loss: 0.3854 - val_accuracy: 0.8212
Epoch 72/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3777 - accuracy: 0.8378 - val_loss: 0.3879 - val_accuracy: 0.8173
Epoch 73/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3777 - accuracy: 0.8378 - val_loss: 0.3886 - val_accuracy: 0.8160
Epoch 74/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3777 - accuracy: 0.8378 - val_loss: 0.3819 - val_accuracy: 0.8291
Epoch 75/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3777 - accuracy: 0.8378 - val_loss: 0.3784 - val_accuracy: 0.8341
Epoch 76/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3777 - accuracy: 0.8378 - val_loss: 0.3776 - val_accuracy: 0.8358
Epoch 77/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3777 - accuracy: 0.8378 - val_loss: 0.3774 - val_accuracy: 0.8376
Epoch 78/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3777 - accuracy: 0.8378 - val_loss: 0.3778 - val_accuracy: 0.8397
Epoch 79/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3776 - accuracy: 0.8378 - val_loss: 0.3787 - val_accuracy: 0.8400
Epoch 80/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3776 - accuracy: 0.8378 - val_loss: 0.3797 - val_accuracy: 0.8404
Epoch 81/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3776 - accuracy: 0.8378 - val_loss: 0.3806 - val_accuracy: 0.8400
Epoch 82/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3776 - accuracy: 0.8378 - val_loss: 0.3811 - val_accuracy: 0.8401
Epoch 83/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3776 - accuracy: 0.8378 - val_loss: 0.3819 - val_accuracy: 0.8400
Epoch 84/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3776 - accuracy: 0.8378 - val_loss: 0.3826 - val_accuracy: 0.8399
Epoch 85/10000
12352/12352 [==============================] - 705s 57ms/step - loss: 0.3776 - accuracy: 0.8378 - val_loss: 0.3834 - val_accuracy: 0.8372
Epoch 86/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3776 - accuracy: 0.8379 - val_loss: 0.3842 - val_accuracy: 0.8353
Epoch 87/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3776 - accuracy: 0.8379 - val_loss: 0.3850 - val_accuracy: 0.8349
Epoch 88/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3776 - accuracy: 0.8379 - val_loss: 0.3859 - val_accuracy: 0.8345
Epoch 89/10000
12352/12352 [==============================] - 704s 57ms/step - loss: 0.3776 - accuracy: 0.8379 - val_loss: 0.3869 - val_accuracy: 0.8322
Epoch 90/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3776 - accuracy: 0.8379 - val_loss: 0.3875 - val_accuracy: 0.8313
Epoch 91/10000
12352/12352 [==============================] - 707s 57ms/step - loss: 0.3776 - accuracy: 0.8379 - val_loss: 0.3879 - val_accuracy: 0.8309
Epoch 92/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3776 - accuracy: 0.8379 - val_loss: 0.3888 - val_accuracy: 0.8278
Epoch 93/10000
12352/12352 [==============================] - 699s 57ms/step - loss: 0.3776 - accuracy: 0.8379 - val_loss: 0.3876 - val_accuracy: 0.8290
Epoch 94/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3776 - accuracy: 0.8379 - val_loss: 0.3866 - val_accuracy: 0.8309
Epoch 95/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3852 - val_accuracy: 0.8317
Epoch 96/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3833 - val_accuracy: 0.8329
Epoch 97/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3813 - val_accuracy: 0.8356
Epoch 98/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3793 - val_accuracy: 0.8370
Epoch 99/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3777 - val_accuracy: 0.8386
Epoch 100/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3769 - val_accuracy: 0.8381
Epoch 101/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3772 - val_accuracy: 0.8362
Epoch 102/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3787 - val_accuracy: 0.8338
Epoch 103/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3815 - val_accuracy: 0.8289
Epoch 104/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3867 - val_accuracy: 0.8187
Epoch 105/10000
12352/12352 [==============================] - 706s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3897 - val_accuracy: 0.8147
Epoch 106/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3936 - val_accuracy: 0.8065
Epoch 107/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3981 - val_accuracy: 0.8008
Epoch 108/10000
12352/12352 [==============================] - 705s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.4018 - val_accuracy: 0.7949
Epoch 109/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.4081 - val_accuracy: 0.7861
Epoch 110/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.4098 - val_accuracy: 0.7828
Epoch 111/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.4060 - val_accuracy: 0.7881
Epoch 112/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3973 - val_accuracy: 0.8013
Epoch 113/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3775 - accuracy: 0.8379 - val_loss: 0.3900 - val_accuracy: 0.8140
Epoch 114/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3854 - val_accuracy: 0.8205
Epoch 115/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3839 - val_accuracy: 0.8236
Epoch 116/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3834 - val_accuracy: 0.8241
Epoch 117/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3811 - val_accuracy: 0.8296
Epoch 118/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3793 - val_accuracy: 0.8329
Epoch 119/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3785 - val_accuracy: 0.8341
Epoch 120/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3774 - val_accuracy: 0.8362
Epoch 121/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3771 - val_accuracy: 0.8368
Epoch 122/10000
12352/12352 [==============================] - 701s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3772 - val_accuracy: 0.8367
Epoch 123/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3774 - val_accuracy: 0.8364
Epoch 124/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3776 - val_accuracy: 0.8358
Epoch 125/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3776 - val_accuracy: 0.8358
Epoch 126/10000
12352/12352 [==============================] - 702s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3776 - val_accuracy: 0.8357
Epoch 127/10000
12352/12352 [==============================] - 703s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3781 - val_accuracy: 0.8349
Epoch 128/10000
12352/12352 [==============================] - 704s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3786 - val_accuracy: 0.8342
Epoch 129/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3799 - val_accuracy: 0.8326
Epoch 130/10000
12352/12352 [==============================] - 700s 57ms/step - loss: 0.3774 - accuracy: 0.8379 - val_loss: 0.3827 - val_accuracy: 0.8266
Training... ends
